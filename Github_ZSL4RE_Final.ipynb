{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpb0mYUFo00r"
      },
      "source": [
        "#Setup Running Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo_I3IcspTKE"
      },
      "source": [
        "##GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58NQemupYfo7"
      },
      "source": [
        "To optimize requirements (Req) classification performance, we considered using a GPU instead of a CPU. GPUs significantly accelerate inference, especially for larger models. In our experimentation, we selected A100 GPU as a running environment, a high-performance A100 GPU, users with Google Colab Pro+ can also utilize T4 and L4 GPUs, though with slightly longer processing times compared to the A100.\n",
        "\n",
        "*  make sure to change the runtime type and select \"A100 GPU\" as a hardware accelerator\n",
        "*  then, verify GPU availability and select a device, please run the following code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUk9GYol2u9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b6837f-03a2-4871-cb6c-cc816a2a235b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU detected at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Setup Running Environment (GPU)\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print(\"No GPU detected!\")\n",
        "else:\n",
        "    print(\"GPU detected at:\", device_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjlKXy4eim9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bab9c9c-8fd1-4300-85cd-d3b0bf559da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: NVIDIA A100-SXM4-40GB\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"GPU not available\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afieyQ0c2H4Y"
      },
      "source": [
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape dropdown. After, re-execute the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTQOECMv2CX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17946dff-b748-451b-84e7-87ebef489c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIWB-FNo9SJn"
      },
      "source": [
        "##Radnom Seed\n",
        "This process is important to ensure reproducibility, we set a fixed random seed (typically 42) for PyTorch, NumPy, and Python's random module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHCzdpFawDMA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "seed = 42  # typical number!\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W19TpOVbpUWk"
      },
      "source": [
        "##TPU (Not-used)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA_eqarffoJc"
      },
      "source": [
        "For optimal performance, consider using a TPU v2 accelerator. TPUs are specifically designed for machine learning workloads and often significantly outperform GPUs and CPUs. While this notebook is currently configured for GPU acceleration, switching to a TPU v2 can potentially boost inference speed and efficiency, especially for larger models or datasets.\n",
        "\n",
        "*P.S. If you switch to TPU make sure to update the code accordingly by using \"strategy\" scoping instead of pushing the code with \"tf.device(device_name)\"*\n",
        "\n",
        "* Change Runtime Type and select \"TPU\" as the hardware accelerator. Ensure you choose the TPU v2 option if available.\n",
        "* Run the following code to check for TPU availability and gather device information:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMkL0BVZaznB"
      },
      "outputs": [],
      "source": [
        "#Setup Running Environment (TPU)\n",
        "import tensorflow as tf\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver) # Use initialize_tpu_system instead of initialize\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSZQZpldpXYl"
      },
      "source": [
        "##Gated HF Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWQMCcITkYzA"
      },
      "source": [
        "Some LLMs used in this Colab, such as Llama and Gemma, require user authentication and valid tokens to access. These models are considered \"gated\" on the Hugging Face Models Hub, meaning they have restricted access to protect intellectual property or control usage. To use these models, you'll need to obtain necessary credentials and follow Hugging Face's guidelines for authentication.\n",
        "\n",
        "* Create users account on Hugging Face\n",
        "* Access these models page on HF, and request to access. The request vetification shall be recived withing 2 hours or less.\n",
        "* Go the user profile page, and select Access Token\n",
        "* Create new token, and copy that token as it will be appeared one time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4fJic8StjzI"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy8fJsw9upmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6fc9d8-7d9e-428d-b808-754a817c7d1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WaadAlhoshan\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ch7ErZovuDx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "with tf.device(device_name):\n",
        "#with strategy.scope():\n",
        "  import os\n",
        "  os.environ[\"HF_AUTH_TOKEN\"] = \"PUT YOUR KEY HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGLneov8pgKv"
      },
      "source": [
        " ## Montoring Performance \"Explanation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_FDFQ5WoTsy"
      },
      "source": [
        "To monitor memory usage and performance within our code, we employ Python packages like tracemalloc and line_profiler. Tracemalloc provides insights into memory allocations, helping identify potential memory leaks and optimize resource utilization. Line profiler, on the other hand, focuses on function-level performance, enabling us to pinpoint time-consuming code sections. By combining these tools, we can effectively analyze efficiency of our code on the selected hardware accelerator (either GPU or TPU).\n",
        "\n",
        "Below are some examples in how to emply these packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQO3gfPaeNfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93f4a64-744d-4cf6-f9de-a04992bdb9ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is output2\n",
            "Total execution time: 9.25 seconds\n",
            "Top 10 memory consumers:\n",
            "<frozen importlib._bootstrap_external>:672: size=61.7 MiB, count=547908, average=118 B\n",
            "<frozen importlib._bootstrap>:241: size=52.0 MiB, count=442403, average=123 B\n",
            "/usr/lib/python3.10/dataclasses.py:432: size=11.5 MiB, count=18751, average=644 B\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/completer.py:2101: size=10.9 MiB, count=137715, average=83 B\n",
            "/usr/lib/python3.10/linecache.py:137: size=10.5 MiB, count=106297, average=104 B\n",
            "<ipython-input-43-6be0b9da56ff>:73: size=2889 KiB, count=92988, average=32 B\n",
            "/usr/lib/python3.10/abc.py:106: size=2197 KiB, count=8533, average=264 B\n",
            "/usr/lib/python3.10/inspect.py:2969: size=1709 KiB, count=22553, average=78 B\n",
            "<frozen importlib._bootstrap_external>:128: size=1549 KiB, count=11656, average=136 B\n",
            "/usr/lib/python3.10/inspect.py:2967: size=1402 KiB, count=23498, average=61 B\n"
          ]
        }
      ],
      "source": [
        "import tracemalloc\n",
        "import time\n",
        "\n",
        "def my_function():\n",
        "  print(\"This is output1\")\n",
        "\n",
        "tracemalloc.start()\n",
        "start_time = time.time()\n",
        "\n",
        "# Your main logic\n",
        "print(\"This is output2\")\n",
        "\n",
        "snapshot = tracemalloc.take_snapshot()\n",
        "top_stats = snapshot.statistics('lineno')\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"Total execution time: {elapsed_time:.2f} seconds\")\n",
        "print(\"Top 10 memory consumers:\")\n",
        "for stat in top_stats[:10]:\n",
        "    print(stat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZ-UoZsDe-bL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "562af856-7dc1-4cfc-da21-3610f7b10af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: line_profiler in /usr/local/lib/python3.10/dist-packages (4.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install line_profiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix76AwwxfAI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abb8a4a-81b3-46c2-f6ef-a0adc1f82539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 1.285e-06 s\n",
            "File: <ipython-input-57-7b006db3f5fd>\n",
            "Function: my_function at line 3\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     3                                           def my_function(x, y):\n",
            "     4                                               # Some code here\n",
            "     5         1       1003.0   1003.0     78.1      result = x * y\n",
            "     6                                               # More code here\n",
            "     7         1        282.0    282.0     21.9      return result\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from line_profiler import LineProfiler\n",
        "\n",
        "def my_function(x, y):\n",
        "    # Some code here\n",
        "    result = x * y\n",
        "    # More code here\n",
        "    return result\n",
        "\n",
        "profiler = LineProfiler()\n",
        "profiler.add_function(my_function)\n",
        "profiler.enable_by_count()\n",
        "\n",
        "my_function(10, 20)\n",
        "\n",
        "profiler.disable_by_count()\n",
        "profiler.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzbZBLdxo6WW"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi #  provides valuable information about GPU utilization, memory consumption, and other performance indicators but cannot be used with TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjS9dM_xpzTN"
      },
      "source": [
        "#Benchmark Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAHe1a1qsFmg"
      },
      "source": [
        "We used selected datasets from primary studies in RE. These datasets have been extensively used in RE to experiment with requirements classification tasks.\n",
        "\n",
        "Please note that the URLs provided for accessing these datasets might become invalid after the publication of this Colab. We strongly encourage retrieving the datasets from their original repositories for future use.\n",
        "\n",
        "================================================================================\n",
        "\n",
        "**Functional and Quality**\n",
        "\n",
        "*dronology.csv*\n",
        "https://drive.google.com/file/d/1yaFD5NIx4De698ok9ryv4EqIW0jPdlEr/view?usp=sharing\n",
        "\n",
        "*leeds.csv*\n",
        "https://drive.google.com/file/d/1EQVynWt1eMlZHNiyKYbjU0FoeVjcJjF7/view?usp=sharing\n",
        "\n",
        "*promise-reclass.csv*\n",
        "https://drive.google.com/file/d/1JsctHwmGrQuP1dXFG1i6XnS6aAtMXeN3/view?usp=sharing\n",
        "\n",
        "*reqview.csv*\n",
        "https://drive.google.com/file/d/1UeE_EVt3PKvMF8fyyM-LruhTHXZINdcQ/view?usp=sharing\n",
        "\n",
        "*wasp.csv*\n",
        "https://drive.google.com/file/d/1-wuKWflxqL3k0tZ0mqQtr0mUXrPPJsCB/view?usp=sharing\n",
        "\n",
        "================================================================================\n",
        "\n",
        "**NFR Multiclass**\n",
        "\n",
        "*PROMISE-NFR.csv*\n",
        "'https://drive.google.com/file/d/1JsctHwmGrQuP1dXFG1i6XnS6aAtMXeN3/view?usp=sharing\n",
        "\n",
        "================================================================================\n",
        "\n",
        "**Security or Not**\n",
        "\n",
        "*SeqReq.csv*\n",
        "\n",
        "\n",
        "================================================================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B15kCj-V7v4A"
      },
      "source": [
        "## Preps Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uQumM5MH90p"
      },
      "outputs": [],
      "source": [
        "#General methods for datasets preps\n",
        "import pandas as pd\n",
        "def read_dataset_from_google(url):\n",
        "  url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
        "  df = pd.read_csv(url)\n",
        "  return df\n",
        "\n",
        "def combine_datasets(dataset_list):\n",
        "  combined_df = pd.concat(dataset_list, ignore_index=True)\n",
        "  return combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ-D0GC9UNSJ"
      },
      "outputs": [],
      "source": [
        "# A function that applies changes to the labels using uppercase or lowercased or captizlied\n",
        "\n",
        "def modify_labels(labels, case):\n",
        "  modified_labels = []\n",
        "  for label in labels:\n",
        "    if case == 'upper':\n",
        "      modified_labels.append(label.upper())\n",
        "    elif case == 'lower':\n",
        "      modified_labels.append(label.lower())\n",
        "    elif case == 'capitalize':\n",
        "      modified_labels.append(label.capitalize())\n",
        "    else:\n",
        "      modified_labels.append(label)\n",
        "  return modified_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JBzUUIqUggh"
      },
      "outputs": [],
      "source": [
        "#A function that applies changes to the requirementtext by adding full stops or remove puncations -- a list of text\n",
        "\n",
        "import string\n",
        "def remove_punctuation(text_string):\n",
        "  # Remove punctuation from the string\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  return text_string.translate(translator)\n",
        "\n",
        "def modify_text(text_list, modification):\n",
        "  modified_texts = []\n",
        "  for text in text_list:\n",
        "    if modification == 'add_full_stops':\n",
        "      modified_texts.append(text + '.')\n",
        "    elif modification == 'remove_punctuation':\n",
        "      modified_texts.append(remove_punctuation(text))\n",
        "    else:\n",
        "      modified_texts.append(text)\n",
        "  return modified_texts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KtWAs16I3bg"
      },
      "source": [
        "## Functional and Quality (Binary)\n",
        "\n",
        "Two datasets is generated as **Functional** binary dataset ```functional_df``` and **Quality** binary dataset ```quality_df```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTVnbT0es26L"
      },
      "outputs": [],
      "source": [
        "\n",
        "datasets_names = [\"dronology.csv\", \"leeds.csv\", \"promise-reclass.csv\", \"reqview.csv\", \"wasp.csv\"]\n",
        "datasets_urls = [ \"ADD SHAREABLE LINK OF EACH DATASET\"] #Or you can import the dataset locally here!\n",
        "\n",
        "def read_datasets(datasets_urls, datasets_names):\n",
        "  datasets = []\n",
        "  for url in datasets_urls:\n",
        "    df = read_dataset_from_google(url)\n",
        "    df[\"DatasetName\"] = datasets_names[datasets_urls.index(url)]\n",
        "    datasets.append(df)\n",
        "  return datasets\n",
        "datasets = read_datasets(datasets_urls, datasets_names)\n",
        "df = combine_datasets(datasets)\n",
        "functional_status = []\n",
        "for index, row in df.iterrows():\n",
        "  if row['IsFunctional'] == 1:\n",
        "    functional_status.append('Functional')\n",
        "  else:\n",
        "    functional_status.append('Non-functional')\n",
        "df['FunctionalStatus'] = functional_status\n",
        "\n",
        "\n",
        "quality_status = []\n",
        "for index, row in df.iterrows():\n",
        "  if row['IsQuality'] == 1:\n",
        "    quality_status.append('Quality')\n",
        "  else:\n",
        "    quality_status.append('Non-quality')\n",
        "df['QualityStatus'] = quality_status\n",
        "\n",
        "# Functional Status DataFrame\n",
        "functional_df = df[['DatasetName', 'ProjectID', 'RequirementText', 'FunctionalStatus']]\n",
        "functional_df = functional_df.rename(columns={'FunctionalStatus': 'Label'})\n",
        "\n",
        "# Quality Status DataFrame\n",
        "quality_df = df[['DatasetName', 'ProjectID', 'RequirementText', 'QualityStatus']]\n",
        "quality_df = quality_df.rename(columns={'QualityStatus': 'Label'})\n",
        "\n",
        "\n",
        "print(\"Functional Status DataFrame:\")\n",
        "#print(functional_df.head())\n",
        "\n",
        "print(\"\\nQuality Status DataFrame:\")\n",
        "#print(quality_df.head())\n",
        "\n",
        "print(\"Functional Status Label Counts:\")\n",
        "print(functional_df['Label'].value_counts())\n",
        "\n",
        "print(\"\\nQuality Status Label Counts:\")\n",
        "print(quality_df['Label'].value_counts())\n",
        "\n",
        "# Re-arrange columns for Functional Status DataFrame\n",
        "functional_df = functional_df[['DatasetName', 'ProjectID', 'RequirementText', 'Label']]\n",
        "# Re-arrange columns for Quality Status DataFrame\n",
        "quality_df = quality_df[['DatasetName', 'ProjectID', 'RequirementText', 'Label']]\n",
        "\n",
        "# Save Functional Status DataFrame to CSV\n",
        "functional_df.to_csv('functional_status_binary.csv', index=False)\n",
        "# Save Quality Status DataFrame to CSV\n",
        "quality_df.to_csv('quality_status_binary.csv', index=False)\n",
        "\n",
        "\n",
        "# ---------Dataset Variations for Functional Binary Classification\n",
        "Functional_None = functional_df.copy()\n",
        "\n",
        "Functional_Remove_Punctuation = functional_df.copy()\n",
        "Functional_Remove_Punctuation['RequirementText'] = modify_text(Functional_Remove_Punctuation['RequirementText'], 'remove_punctuation')\n",
        "\n",
        "Functional_Add_FullStops = functional_df.copy()\n",
        "Functional_Add_FullStops['RequirementText'] = modify_text(Functional_Add_FullStops['RequirementText'], 'add_full_stops')\n",
        "\n",
        "Functional_Labels_Uppercase = functional_df.copy()\n",
        "Functional_Labels_Uppercase['Label'] = modify_labels(Functional_Labels_Uppercase['Label'], 'upper')\n",
        "\n",
        "Functional_Labels_Lowercase = functional_df.copy()\n",
        "Functional_Labels_Lowercase['Label'] = modify_labels(Functional_Labels_Lowercase['Label'], 'lower')\n",
        "\n",
        "Functional_Labels_Capitalized = functional_df.copy()\n",
        "Functional_Labels_Capitalized['Label'] = modify_labels(Functional_Labels_Capitalized['Label'], 'capitalize')\n",
        "\n",
        "\n",
        "# ---------Dataset Variations for Quality Binary Classification\n",
        "Quality_None = quality_df.copy()\n",
        "\n",
        "Quality_Remove_Punctuation = quality_df.copy()\n",
        "Quality_Remove_Punctuation['RequirementText'] = modify_text(Quality_Remove_Punctuation['RequirementText'], 'remove_punctuation')\n",
        "\n",
        "Quality_Add_FullStops = quality_df.copy()\n",
        "Quality_Add_FullStops['RequirementText'] = modify_text(Quality_Add_FullStops['RequirementText'], 'add_full_stops')\n",
        "\n",
        "Quality_Labels_Uppercase = quality_df.copy()\n",
        "Quality_Labels_Uppercase['Label'] = modify_labels(Quality_Labels_Uppercase['Label'], 'upper')\n",
        "\n",
        "Quality_Labels_Lowercase = quality_df.copy()\n",
        "Quality_Labels_Lowercase['Label'] = modify_labels(Quality_Labels_Lowercase['Label'], 'lower')\n",
        "\n",
        "Quality_Labels_Capitalized = quality_df.copy()\n",
        "Quality_Labels_Capitalized['Label'] = modify_labels(Quality_Labels_Capitalized['Label'], 'capitalize')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMMCt_MffdBj"
      },
      "outputs": [],
      "source": [
        "print(\"\\ Functional_Labels_Uppercase Label Counts:\")\n",
        "print(Functional_Labels_Uppercase['Label'].value_counts())\n",
        "print(\"\\nFunctional_Labels_Lowercase Label Counts:\")\n",
        "print(Functional_Labels_Lowercase['Label'].value_counts())\n",
        "print(\"\\nFunctional_Labels_Capitalized Label Counts:\")\n",
        "print(Functional_Labels_Capitalized['Label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leQhe1G7fOja"
      },
      "outputs": [],
      "source": [
        "print(\"\\ Quality_Labels_Uppercase Label Counts:\")\n",
        "print(Quality_Labels_Uppercase['Label'].value_counts())\n",
        "print(\"\\nQuality_Labels_Lowercase Label Counts:\")\n",
        "print(Quality_Labels_Lowercase['Label'].value_counts())\n",
        "print(\"\\nQuality_Labels_Capitalized Label Counts:\")\n",
        "print(Quality_Labels_Capitalized['Label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCdtEMLdSRQp"
      },
      "outputs": [],
      "source": [
        "# Add Label Definition for Functional Status DataFrame\n",
        "Functional_None['Label Definition'] = Functional_None['Label'].apply(lambda x: 'Functional requirements (FRs) specify the functions of the system.' if x == 'Functional' else 'Non-functional requirements (NFRs) define how the system performs its intended functions.')\n",
        "Functional_Remove_Punctuation['Label Definition'] = Functional_Remove_Punctuation['Label'].apply(lambda x: 'Functional requirements (FRs) specify the functions of the system.' if x == 'Functional' else 'Non-functional requirements (NFRs) define how the system performs its intended functions.')\n",
        "Functional_Add_FullStops['Label Definition'] = Functional_Add_FullStops['Label'].apply(lambda x: 'Functional requirements (FRs) specify the functions of the system.' if x == 'Functional' else 'Non-functional requirements (NFRs) define how the system performs its intended functions.')\n",
        "Functional_Labels_Uppercase['Label Definition'] = Functional_Labels_Uppercase['Label'].apply(lambda x: 'Functional requirements (FRs) specify the functions of the system.' if x == 'FUNCTIONAL' else 'Non-functional requirements (NFRs) define how the system performs its intended functions.')\n",
        "Functional_Labels_Lowercase['Label Definition'] = Functional_Labels_Lowercase['Label'].apply(lambda x: 'Functional requirements (FRs) specify the functions of the system.' if x == 'functional' else 'Non-functional requirements (NFRs) define how the system performs its intended functions.')\n",
        "Functional_Labels_Capitalized['Label Definition'] = Functional_Labels_Capitalized['Label'].apply(lambda x: 'Functional requirements (FRs) specify the functions of the system.' if x == 'Functional' else 'Non-functional requirements (NFRs) define how the system performs its intended functions.')\n",
        "\n",
        "\n",
        "# Add Label Definition for Quality Status DataFrame\n",
        "Quality_None['Label Definition'] = Quality_None['Label'].apply(lambda x: 'Quality requirements (QRs) define how well the system performs its intended functions.' if x == 'Quality' else 'Non-quality requirements are the NFRs that are not the quality requirements.')\n",
        "Quality_Remove_Punctuation['Label Definition'] = Quality_Remove_Punctuation['Label'].apply(lambda x: 'Quality requirements (QRs) define how well the system performs its intended functions.' if x == 'Quality' else 'Non-quality requirements are the NFRs that are not the quality requirements.')\n",
        "Quality_Add_FullStops['Label Definition'] = Quality_Add_FullStops['Label'].apply(lambda x: 'Quality requirements (QRs) define how well the system performs its intended functions.' if x == 'Quality' else 'Non-quality requirements are the NFRs that are not the quality requirements.')\n",
        "Quality_Labels_Uppercase['Label Definition'] = Quality_Labels_Uppercase['Label'].apply(lambda x: 'Quality requirements (QRs) define how well the system performs its intended functions.' if x == 'QUALITY' else 'Non-quality requirements are the NFRs that are not the quality requirements.')\n",
        "Quality_Labels_Lowercase['Label Definition'] = Quality_Labels_Lowercase['Label'].apply(lambda x: 'Quality requirements (QRs) define how well the system performs its intended functions.' if x == 'quality' else 'Non-quality requirements are the NFRs that are not the quality requirements.')\n",
        "Quality_Labels_Capitalized['Label Definition'] = Quality_Labels_Capitalized['Label'].apply(lambda x: 'Quality requirements (QRs) define how well the system performs its intended functions.' if x == 'Quality' else 'Non-quality requirements are the NFRs that are not the quality requirements.')\n",
        "\n",
        "print(\"Functional Status DataFrame with Label Definition:\")\n",
        "print(Functional_None.head())\n",
        "\n",
        "print(\"\\nQuality Status DataFrame with Label Definition:\")\n",
        "print(Quality_None.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW4xYNHfM3u7"
      },
      "source": [
        "## Security (Binary)\n",
        "\n",
        "Another binary dataset is generated as **Sequrity** binary dataset ```seq_df```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwdZw6z9KfE_"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"SeqReq\"\n",
        "seq_df = read_dataset_from_google('[ \"ADD SHAREABLE LINK OF EACH DATASET\"] #Or you can import the dataset locally here!')\n",
        "seq_df['DatasetName'] = dataset_name\n",
        "seq_df['Label'] = seq_df['Label'].apply(lambda x: 'Security' if x == 'sec' else 'Non-Security')\n",
        "seq_df = seq_df[['DatasetName', 'ProjectID', 'RequirementText', 'Label']]\n",
        "print(seq_df.head())\n",
        "print(len(seq_df.values))\n",
        "# Save DataFrame to CSV\n",
        "seq_df.to_csv('SeqReq.csv', index=False)\n",
        "print(\"\\nSequrity Label Counts:\")\n",
        "print(seq_df['Label'].value_counts())\n",
        "\n",
        "# ---------Dataset Variations for SeqReq Binary Classification\n",
        "SeqReq_None = seq_df.copy()\n",
        "\n",
        "SeqReq_Remove_Punctuation = seq_df.copy()\n",
        "SeqReq_Remove_Punctuation['RequirementText'] = modify_text(SeqReq_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "SeqReq_Add_FullStops = seq_df.copy()\n",
        "SeqReq_Add_FullStops['RequirementText'] = modify_text(SeqReq_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "SeqReq_Labels_Uppercase = seq_df.copy()\n",
        "SeqReq_Labels_Uppercase['Label'] = modify_labels(SeqReq_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "SeqReq_Labels_Lowercase = seq_df.copy()\n",
        "SeqReq_Labels_Lowercase['Label'] = modify_labels(SeqReq_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "SeqReq_Labels_Capitalized = seq_df.copy()\n",
        "SeqReq_Labels_Capitalized['Label'] = modify_labels(SeqReq_Labels_Capitalized['Label'],'capitalize')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMo3afCaS5hG"
      },
      "outputs": [],
      "source": [
        "# Add Label Definition for SeqReq_None Status DataFrame\n",
        "SeqReq_None['Label Definition'] = SeqReq_None['Label'].apply(lambda x: 'Security requirements (SRs) are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'Security' else 'Non-security requirements are any requirements that are not the security requirements.')\n",
        "SeqReq_Remove_Punctuation['Label Definition'] = SeqReq_Remove_Punctuation['Label'].apply(lambda x: 'Security requirements (SRs) are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'Security' else 'Non-security requirements are any requirements that are not the security requirements.')\n",
        "SeqReq_Add_FullStops['Label Definition'] = SeqReq_Add_FullStops['Label'].apply(lambda x: 'Security requirements (SRs) are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'Security' else 'Non-security requirements are any requirements that are not the security requirements.')\n",
        "SeqReq_Labels_Uppercase['Label Definition'] = SeqReq_Labels_Uppercase['Label'].apply(lambda x: 'Security requirements (SRs) are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'SECURITY' else 'Non-security requirements are any requirements that are not the security requirements.')\n",
        "SeqReq_Labels_Lowercase['Label Definition'] = SeqReq_Labels_Lowercase['Label'].apply(lambda x: 'Security requirements (SRs) are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'security' else 'Non-security requirements are any requirements that are not the security requirements.')\n",
        "SeqReq_Labels_Capitalized['Label Definition'] = SeqReq_Labels_Capitalized['Label'].apply(lambda x: 'Security requirements (SRs) are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'Security' else 'Non-security requirements are any requirements that are not the security requirements.')\n",
        "\n",
        "print(\"SeqReq Status DataFrame with Label Definition:\")\n",
        "print(SeqReq_None.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEx6DVmCNGUj"
      },
      "source": [
        "## Non-functional Classes-NFR (Multi)\n",
        "\n",
        "The only multiclass dataset employed for this experiments as **NFR** multiclass dataset ```NFR_df```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVRQt6dHF6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d9cd90-7525-4c1b-9b60-44f20bf08e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      DatasetName  ProjectID  \\\n",
            "0  PROMISE-NFR-V2          1   \n",
            "1  PROMISE-NFR-V2          1   \n",
            "2  PROMISE-NFR-V2          1   \n",
            "3  PROMISE-NFR-V2          1   \n",
            "4  PROMISE-NFR-V2          1   \n",
            "\n",
            "                                     RequirementText          Label  \n",
            "0  'The system shall refresh the display every 60...    Performance  \n",
            "1  'The application shall match the color of the ...  Look and Feel  \n",
            "2  'If projected the data must be readable. On a ...      Usability  \n",
            "3  'The product shall be available during normal ...   Availability  \n",
            "4  'If projected the data must be understandable....      Usability  \n",
            "\n",
            "NFR Label Counts:\n",
            "Label\n",
            "Usability          67\n",
            "Security           66\n",
            "Operational        62\n",
            "Performance        54\n",
            "Look and Feel      38\n",
            "Availability       21\n",
            "Scalability        21\n",
            "Maintainability    17\n",
            "Legal              13\n",
            "Fault Tolerance    10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "dataset_name = \"PROMISE-NFR-V2\"\n",
        "NFR_df = read_dataset_from_google('[ \"ADD SHAREABLE LINK OF EACH DATASET\"] #Or you can import the dataset locally here!')\n",
        "NFR_df['DatasetName'] = dataset_name\n",
        "NFR_df.drop(columns=['IsFunctional'], inplace=True)\n",
        "NFR_df.drop(columns=['IsQuality'], inplace=True)\n",
        "# Replace class names with full names\n",
        "NFR_df['Class'] = NFR_df['Class'].replace({\n",
        "    'PE': 'Performance',\n",
        "    'SE': 'Security',\n",
        "    'O': 'Operational',\n",
        "    'SC': 'Scalability',\n",
        "    'US': 'Usability',\n",
        "    'MN': 'Maintainability',\n",
        "    #'RE': 'Reliability',\n",
        "    'LF': 'Look and Feel',\n",
        "    'A': 'Availability',\n",
        "    'PO': 'Portability',\n",
        "    'L' : 'Legal',\n",
        "    'FT' : 'Fault Tolerance',\n",
        "    'F': 'Functional'\n",
        "})\n",
        "NFR_df = NFR_df.rename(columns={'Class': 'Label'})\n",
        "# Re-arrange columns\n",
        "NFR_df = NFR_df[['DatasetName', 'ProjectID', 'RequirementText', 'Label']]\n",
        "NFR_df = NFR_df[NFR_df['Label'] != 'Portability']\n",
        "NFR_df = NFR_df[NFR_df['Label'] != 'Functional']\n",
        "print(NFR_df.head())\n",
        "# Save DataFrame to CSV\n",
        "NFR_df.to_csv('PROMISE-NFR-v2.csv', index=False)\n",
        "print(\"\\nNFR Label Counts:\")\n",
        "print(NFR_df['Label'].value_counts())\n",
        "\n",
        "# ---------Dataset Variations for PROMISE NFR Multi Classification\n",
        "NFR_None = NFR_df.copy()\n",
        "\n",
        "NFR_Remove_Punctuation = NFR_df.copy()\n",
        "NFR_Remove_Punctuation['RequirementText'] = modify_text(NFR_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "NFR_Add_FullStops = NFR_df.copy()\n",
        "NFR_Add_FullStops['RequirementText'] = modify_text(NFR_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "NFR_Labels_Uppercase = NFR_df.copy()\n",
        "NFR_Labels_Uppercase['Label'] = modify_labels(NFR_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "NFR_Labels_Lowercase = NFR_df.copy()\n",
        "NFR_Labels_Lowercase['Label'] = modify_labels(NFR_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "NFR_Labels_Capitalized = NFR_df.copy()\n",
        "NFR_Labels_Capitalized['Label'] = modify_labels(NFR_Labels_Capitalized['Label'],'capitalize')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfwtqOD3iQi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dcc91d6-22c7-4737-a1d1-3b0600e61ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\ NFR_Remove_Punctuation Label Counts:\n",
            "Label\n",
            "Usability          67\n",
            "Security           66\n",
            "Operational        62\n",
            "Performance        54\n",
            "Look and Feel      38\n",
            "Availability       21\n",
            "Scalability        21\n",
            "Maintainability    17\n",
            "Legal              13\n",
            "Fault Tolerance    10\n",
            "Name: count, dtype: int64\n",
            "\\ NFR_Add_FullStops Label Counts:\n",
            "Label\n",
            "Usability          67\n",
            "Security           66\n",
            "Operational        62\n",
            "Performance        54\n",
            "Look and Feel      38\n",
            "Availability       21\n",
            "Scalability        21\n",
            "Maintainability    17\n",
            "Legal              13\n",
            "Fault Tolerance    10\n",
            "Name: count, dtype: int64\n",
            "\\ NFR_Labels_Uppercase Label Counts:\n",
            "Label\n",
            "USABILITY          67\n",
            "SECURITY           66\n",
            "OPERATIONAL        62\n",
            "PERFORMANCE        54\n",
            "LOOK AND FEEL      38\n",
            "AVAILABILITY       21\n",
            "SCALABILITY        21\n",
            "MAINTAINABILITY    17\n",
            "LEGAL              13\n",
            "FAULT TOLERANCE    10\n",
            "Name: count, dtype: int64\n",
            "\n",
            "NFR_Labels_Lowercase Label Counts:\n",
            "Label\n",
            "usability          67\n",
            "security           66\n",
            "operational        62\n",
            "performance        54\n",
            "look and feel      38\n",
            "availability       21\n",
            "scalability        21\n",
            "maintainability    17\n",
            "legal              13\n",
            "fault tolerance    10\n",
            "Name: count, dtype: int64\n",
            "\n",
            "NFR_Labels_Capitalized Label Counts:\n",
            "Label\n",
            "Usability          67\n",
            "Security           66\n",
            "Operational        62\n",
            "Performance        54\n",
            "Look and feel      38\n",
            "Availability       21\n",
            "Scalability        21\n",
            "Maintainability    17\n",
            "Legal              13\n",
            "Fault tolerance    10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#print(\"\\ NFR_Labels_None Label Counts:\")\n",
        "#print(NFR_None['Label'].value_counts())\n",
        "print(\"\\ NFR_Remove_Punctuation Label Counts:\")\n",
        "print(NFR_Remove_Punctuation['Label'].value_counts())\n",
        "print(\"\\ NFR_Add_FullStops Label Counts:\")\n",
        "print(NFR_Add_FullStops['Label'].value_counts())\n",
        "print(\"\\ NFR_Labels_Uppercase Label Counts:\")\n",
        "print(NFR_Labels_Uppercase['Label'].value_counts())\n",
        "print(\"\\nNFR_Labels_Lowercase Label Counts:\")\n",
        "print(NFR_Labels_Lowercase['Label'].value_counts())\n",
        "print(\"\\nNFR_Labels_Capitalized Label Counts:\")\n",
        "print(NFR_Labels_Capitalized['Label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSXFERcnTE0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5937b033-f5fc-4044-af79-5b1efa9d5b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NFR Status DataFrame with Label Definition:\n",
            "      DatasetName  ProjectID  \\\n",
            "0  PROMISE-NFR-V2          1   \n",
            "1  PROMISE-NFR-V2          1   \n",
            "2  PROMISE-NFR-V2          1   \n",
            "3  PROMISE-NFR-V2          1   \n",
            "4  PROMISE-NFR-V2          1   \n",
            "\n",
            "                                     RequirementText          Label  \n",
            "0  'The system shall refresh the display every 60...    Performance  \n",
            "1  'The application shall match the color of the ...  Look and Feel  \n",
            "2  'If projected the data must be readable. On a ...      Usability  \n",
            "3  'The product shall be available during normal ...   Availability  \n",
            "4  'If projected the data must be understandable....      Usability  \n"
          ]
        }
      ],
      "source": [
        "# Add Label Definition for NFR_None Status DataFrame\n",
        "\n",
        "'''\n",
        "NFR_None['Label Definition'] = NFR_None['Label'].apply(lambda x:\n",
        "    'Performance requirements are quality requirements that specify the performance measure of the system.' if x == 'Performance' else (\n",
        "    'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'Security' else (\n",
        "    'Operational requirements define the specific conditions and situations under which the system will function.' if x == 'Operational' else (\n",
        "    'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.' if x == 'Scalability' else (\n",
        "    'Usability requirements are quality requirements that define what a system has to do to support users task performance.' if x == 'Usability' else (\n",
        "    'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.' if x == 'Maintainability' else (\n",
        "    'Reliability requirements are quality requirements that specify how likely a system would run without a failure for a given period of time under predefined conditions.' if x == 'Reliability' else (\n",
        "    'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.' if x == 'Look and Feel' else (\n",
        "    'Availability requirements are quality requirements that ensure the maximum operational time of a system.' if x == 'Availability' else (\n",
        "    'Portability requirements define how easy it is to transport a system from its current hardware or software environment to another environment.' if x == 'Portability' else (\n",
        "    'Legal requirements define a system legal conformity to data privacy, regulations and standards.' if x == 'Legal' else (\n",
        "    'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.' if x == 'Fault Tolerance' else (\n",
        "    'Functional requirements (FRs) specify the functions of the system.' if x == 'Functional' else 'Unknown'\n",
        "    ))))))))))))\n",
        ")\n",
        "'''\n",
        "\n",
        "NFR_Remove_Punctuation['Label Definition'] = NFR_Remove_Punctuation['Label'].apply(lambda x:\n",
        "    'Performance requirements are quality requirements that specify the performance measure of the system.' if x == 'Performance' else (\n",
        "    'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'Security' else (\n",
        "    'Operational requirements define the specific conditions and situations under which the system will function.' if x == 'Operational' else (\n",
        "    'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.' if x == 'Scalability' else (\n",
        "    'Usability requirements are quality requirements that define what a system has to do to support users task performance.' if x == 'Usability' else (\n",
        "    'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.' if x == 'Maintainability' else (\n",
        "    'Reliability requirements are quality requirements that specify how likely a system would run without a failure for a given period of time under predefined conditions.' if x == 'Reliability' else (\n",
        "    'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.' if x == 'Look and Feel' else (\n",
        "    'Availability requirements are quality requirements that ensure the maximum operational time of a system.' if x == 'Availability' else (\n",
        "    'Portability requirements define how easy it is to transport a system from its current hardware or software environment to another environment.' if x == 'Portability' else (\n",
        "    'Legal requirements define a system legal conformity to data privacy, regulations and standards.' if x == 'Legal' else (\n",
        "    'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.' if x == 'Fault Tolerance' else (\n",
        "    'Functional requirements (FRs) specify the functions of the system.' if x == 'Functional' else 'Unknown'\n",
        "    ))))))))))))\n",
        ")\n",
        "\n",
        "NFR_Add_FullStops['Label Definition'] = NFR_Add_FullStops['Label'].apply(lambda x:\n",
        "    'Performance requirements are quality requirements that specify the performance measure of the system.' if x == 'Performance' else (\n",
        "    'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'Security' else (\n",
        "    'Operational requirements define the specific conditions and situations under which the system will function.' if x == 'Operational' else (\n",
        "    'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.' if x == 'Scalability' else (\n",
        "    'Usability requirements are quality requirements that define what a system has to do to support users task performance.' if x == 'Usability' else (\n",
        "    'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.' if x == 'Maintainability' else (\n",
        "    'Reliability requirements are quality requirements that specify how likely a system would run without a failure for a given period of time under predefined conditions.' if x == 'Reliability' else (\n",
        "    'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.' if x == 'Look and Feel' else (\n",
        "    'Availability requirements are quality requirements that ensure the maximum operational time of a system.' if x == 'Availability' else (\n",
        "    'Portability requirements define how easy it is to transport a system from its current hardware or software environment to another environment.' if x == 'Portability' else (\n",
        "    'Legal requirements define a system legal conformity to data privacy, regulations and standards.' if x == 'Legal' else (\n",
        "    'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.' if x == 'Fault Tolerance' else (\n",
        "    'Functional requirements (FRs) specify the functions of the system.' if x == 'Functional' else 'Unknown'\n",
        "    ))))))))))))\n",
        ")\n",
        "\n",
        "NFR_Labels_Uppercase['Label Definition'] = NFR_Labels_Uppercase['Label'].apply(lambda x:'Performance requirements are quality requirements that specify the performance measure of the system.' if x == 'PERFORMANCE' else (\n",
        "    'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'SECURITY' else (\n",
        "    'Operational requirements define the specific conditions and situations under which the system will function.' if x == 'OPERATIONAL' else (\n",
        "    'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.' if x == 'SCALABILITY' else (\n",
        "    'Usability requirements are quality requirements that define what a system has to do to support users task performance.' if x == 'USABILITY' else (\n",
        "    'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.' if x == 'MAINTAINABILITY' else (\n",
        "    'Reliability requirements are quality requirements that specify how likely a system would run without a failure for a given period of time under predefined conditions.' if x == 'RELIABILITY' else (\n",
        "    'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.' if x == 'LOOK AND FEEL' else (\n",
        "    'Availability requirements are quality requirements that ensure the maximum operational time of a system.' if x == 'AVAILABILITY' else (\n",
        "    'Portability requirements define how easy it is to transport a system from its current hardware or software environment to another environment.' if x == 'PORTABILITY' else (\n",
        "    'Legal requirements define a system legal conformity to data privacy, regulations and standards.' if x == 'LEGAL' else (\n",
        "    'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.' if x == 'FAULT TOLERANCE' else (\n",
        "    'Functional requirements (FRs) specify the functions of the system.' if x == 'FUNCTIONAL' else 'Unknown'\n",
        "    ))))))))))))\n",
        ")\n",
        "\n",
        "NFR_Labels_Lowercase['Label Definition'] = NFR_Labels_Lowercase['Label'].apply(lambda x: 'Performance requirements are quality requirements that specify the performance measure of the system.' if x == 'performance' else (\n",
        "    'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'security' else (\n",
        "    'Operational requirements define the specific conditions and situations under which the system will function.' if x == 'operational' else (\n",
        "    'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.' if x == 'scalability' else (\n",
        "    'Usability requirements are quality requirements that define what a system has to do to support users task performance.' if x == 'usability' else (\n",
        "    'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.' if x == 'maintainability' else (\n",
        "    'Reliability requirements are quality requirements that specify how likely a system would run without a failure for a given period of time under predefined conditions.' if x == 'reliability' else (\n",
        "    'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.' if x == 'look and feel' else (\n",
        "    'Availability requirements are quality requirements that ensure the maximum operational time of a system.' if x == 'availability' else (\n",
        "    'Portability requirements define how easy it is to transport a system from its current hardware or software environment to another environment.' if x == 'portability' else (\n",
        "    'Legal requirements define a system legal conformity to data privacy, regulations and standards.' if x == 'legal' else (\n",
        "    'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.' if x == 'fault tolerance' else (\n",
        "    'Functional requirements (FRs) specify the functions of the system.' if x == 'functional' else 'Unknown'\n",
        "    ))))))))))))\n",
        "\n",
        ")\n",
        "\n",
        "NFR_Labels_Capitalized['Label Definition'] = NFR_Labels_Capitalized['Label'].apply(lambda x:\n",
        "    'Performance requirements are quality requirements that specify the performance measure of the system.' if x == 'Performance' else (\n",
        "    'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'Security' else (\n",
        "    'Operational requirements define the specific conditions and situations under which the system will function.' if x == 'Operational' else (\n",
        "    'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.' if x == 'Scalability' else (\n",
        "    'Usability requirements are quality requirements that define what a system has to do to support users task performance.' if x == 'Usability' else (\n",
        "    'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.' if x == 'Maintainability' else (\n",
        "    'Reliability requirements are quality requirements that specify how likely a system would run without a failure for a given period of time under predefined conditions.' if x == 'Reliability' else (\n",
        "    'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.' if x == 'Look and feel' else (\n",
        "    'Availability requirements are quality requirements that ensure the maximum operational time of a system.' if x == 'Availability' else (\n",
        "    'Portability requirements define how easy it is to transport a system from its current hardware or software environment to another environment.' if x == 'Portability' else (\n",
        "    'Legal requirements define a system legal conformity to data privacy, regulations and standards.' if x == 'Legal' else (\n",
        "    'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.' if x == 'Fault tolerance' else (\n",
        "    'Functional requirements (FRs) specify the functions of the system.' if x == 'Functional' else 'Unknown'\n",
        "    ))))))))))))\n",
        ")\n",
        "print(\"NFR Status DataFrame with Label Definition:\")\n",
        "print(NFR_None.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVgv_GaUIljT"
      },
      "outputs": [],
      "source": [
        "# print any df with any unkown defintion and show which label\n",
        "\n",
        "# Check for unknown definitions in each DataFrame\n",
        "dfs_to_check = [NFR_Remove_Punctuation, NFR_Add_FullStops,\n",
        "               NFR_Labels_Uppercase, NFR_Labels_Lowercase, NFR_Labels_Capitalized]\n",
        "\n",
        "for df in dfs_to_check:\n",
        "  unknown_definitions = df[df['Label Definition'] == 'Unknown']\n",
        "  if not unknown_definitions.empty:\n",
        "    print(f\"Found unknown definitions in DataFrame:\")\n",
        "    print(unknown_definitions[['Label', 'Label Definition']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXH0dHAkknm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199bc329-a5eb-4e38-f0db-838c0e75cb41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NFR_Remove_Punctuation has 'Unknown' label definitions: False\n",
            "NFR_Add_FullStops has 'Unknown' label definitions: False\n",
            "NFR_Labels_Uppercase has 'Unknown' label definitions: False\n",
            "NFR_Labels_Lowercase has 'Unknown' label definitions: False\n",
            "NFR_Labels_Capitalized has 'Unknown' label definitions: False\n"
          ]
        }
      ],
      "source": [
        "#check if there is and Unknown as label defintions for all NFR dfs\n",
        "\n",
        "# Check for 'Unknown' in Label Definition for all NFR DataFrames\n",
        "#print(\"NFR_None has 'Unknown' label definitions:\", NFR_None['Label Definition'].str.contains('Unknown').any())\n",
        "print(\"NFR_Remove_Punctuation has 'Unknown' label definitions:\", NFR_Remove_Punctuation['Label Definition'].str.contains('Unknown').any())\n",
        "print(\"NFR_Add_FullStops has 'Unknown' label definitions:\", NFR_Add_FullStops['Label Definition'].str.contains('Unknown').any())\n",
        "print(\"NFR_Labels_Uppercase has 'Unknown' label definitions:\", NFR_Labels_Uppercase['Label Definition'].str.contains('Unknown').any())\n",
        "print(\"NFR_Labels_Lowercase has 'Unknown' label definitions:\", NFR_Labels_Lowercase['Label Definition'].str.contains('Unknown').any())\n",
        "print(\"NFR_Labels_Capitalized has 'Unknown' label definitions:\", NFR_Labels_Capitalized['Label Definition'].str.contains('Unknown').any())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjUGUGb8BzR3"
      },
      "source": [
        "### Multiclass Dataset Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ1E5vUUKDyL"
      },
      "source": [
        "#### Functional vs NFR classes in PROMISE -- Not needed already included in Functional Binary (1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0LXK8jNJ40a"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Functional_NFR_None = NFR_None.copy()\n",
        "Functional_NFR_None['Label'] = Functional_NFR_None['Label'].apply(lambda x: x if x == 'Functional' else 'Non-Functional')\n",
        "Functional_NFR_None['Label Definition'] = Functional_NFR_None['Label'].apply(lambda x: 'Functional requirements (FRs) specify the functions of the system.' if x == 'Functional' else 'Non-functional requirements (NFRs) define how the system performs its intended functions.')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRb1ZQjfKJdD"
      },
      "source": [
        "#### NFR Classes (excluding Functional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAKyyLnPVLy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a245ad-f783-43de-d960-15a53a75e7f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "Usability          67\n",
            "Security           66\n",
            "Operational        62\n",
            "Performance        54\n",
            "Look and feel      38\n",
            "Availability       21\n",
            "Scalability        21\n",
            "Maintainability    17\n",
            "Legal              13\n",
            "Fault tolerance    10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Copying dataframes from NFR dfs by excluding Functional\n",
        "\n",
        "# Exclude 'Functional' label\n",
        "#NFR_None_NoFunc = NFR_None[NFR_None['Label'] != 'Functional'].copy()\n",
        "NFR_Remove_Punctuation_NoFunc = NFR_Remove_Punctuation[NFR_Remove_Punctuation['Label'] != 'Functional'].copy()\n",
        "NFR_Add_FullStops_NoFunc = NFR_Add_FullStops[NFR_Add_FullStops['Label'] != 'Functional'].copy()\n",
        "NFR_Labels_Uppercase_NoFunc = NFR_Labels_Uppercase[NFR_Labels_Uppercase['Label'] != 'FUNCTIONAL'].copy()\n",
        "NFR_Labels_Lowercase_NoFunc = NFR_Labels_Lowercase[NFR_Labels_Lowercase['Label'] != 'functional'].copy()\n",
        "NFR_Labels_Capitalized_NoFunc = NFR_Labels_Capitalized[NFR_Labels_Capitalized['Label'] != 'Functional'].copy()\n",
        "\n",
        "# Verify the changes\n",
        "print(NFR_Labels_Capitalized_NoFunc['Label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jOBN7NuwLjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "2322abb7-1eed-4762-d4cc-9d8d62941422"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "USABILITY          67\n",
              "SECURITY           66\n",
              "OPERATIONAL        62\n",
              "PERFORMANCE        54\n",
              "LOOK AND FEEL      38\n",
              "AVAILABILITY       21\n",
              "SCALABILITY        21\n",
              "MAINTAINABILITY    17\n",
              "LEGAL              13\n",
              "FAULT TOLERANCE    10\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>USABILITY</th>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SECURITY</th>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OPERATIONAL</th>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PERFORMANCE</th>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOOK AND FEEL</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AVAILABILITY</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCALABILITY</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAINTAINABILITY</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEGAL</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAULT TOLERANCE</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "NFR_Labels_Uppercase_NoFunc['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SDp-AR0KQXE"
      },
      "source": [
        "#### NFR class as one vs rest (OVR) distrubution (excluding Functional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTUBm-EI19-S"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create XXX_NFR_None_NoFunc dataframes\n",
        "Performance_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Performance_NFR_None_NoFunc['Label'] = Performance_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Performance' else 'Non-performance')\n",
        "Security_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Security_NFR_None_NoFunc['Label'] = Security_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Security' else 'Non-security')\n",
        "Operational_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Operational_NFR_None_NoFunc['Label'] = Operational_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Operational' else 'Non-operational')\n",
        "\n",
        "Scalability_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Scalability_NFR_None_NoFunc['Label'] = Scalability_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Scalability' else 'Non-scalability')\n",
        "Usability_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Usability_NFR_None_NoFunc['Label'] = Usability_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Usability' else 'Non-usability')\n",
        "Maintainability_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Maintainability_NFR_None_NoFunc['Label'] = Maintainability_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Maintainability' else 'Non-maintainability')\n",
        "\n",
        "Look_and_Feel_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Look_and_Feel_NFR_None_NoFunc['Label'] = Look_and_Feel_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Look and Feel' else 'Non-Look and Feel')\n",
        "Availability_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Availability_NFR_None_NoFunc['Label'] = Availability_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Availability' else 'Non-availability')\n",
        "Portability_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Portability_NFR_None_NoFunc['Label'] = Portability_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Portability' else 'Non-portability')\n",
        "\n",
        "Fault_Tolerance_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Fault_Tolerance_NFR_None_NoFunc['Label'] = Fault_Tolerance_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Fault Tolerance' else 'Non-Fault Tolerance')\n",
        "Legal_NFR_None_NoFunc = NFR_None_NoFunc.copy()\n",
        "Legal_NFR_None_NoFunc['Label'] = Legal_NFR_None_NoFunc['Label'].apply(lambda x: x if x == 'Legal' else 'Non-Legal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZnQQfHw_yps"
      },
      "outputs": [],
      "source": [
        "#adding defintions label\n",
        "Performance_NFR_None_NoFunc['Label Definition'] = Performance_NFR_None_NoFunc['Label'].apply(lambda x: 'Performance requirements are quality requirements that specify the performance measure of the system.' if x == 'Performance' else 'Non-performance requirements are quality requirements that do not specify any performance measures of the system.')\n",
        "Security_NFR_None_NoFunc['Label Definition'] = Security_NFR_None_NoFunc['Label'].apply(lambda x: 'Security requirements (SRs) are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.' if x == 'Security' else 'Non-security requirements are any requirements that are not the security requirements.')\n",
        "Operational_NFR_None_NoFunc['Label Definition'] = Operational_NFR_None_NoFunc['Label'].apply(lambda x: 'Operational requirements define the specific conditions and situations under which the system will function.' if x == 'Operational' else 'Non-operational any requirement that do not discuss operational conditions and situations.')\n",
        "\n",
        "Scalability_NFR_None_NoFunc['Label Definition'] = Scalability_NFR_None_NoFunc['Label'].apply(lambda x: 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.' if x == 'Scalability' else 'Non-scalability requirements are any requirements that do not discuss system scalability requirements.')\n",
        "Usability_NFR_None_NoFunc['Label Definition'] = Usability_NFR_None_NoFunc['Label'].apply(lambda x: 'Usability requirements are quality requirements that define what a system has to do to support users task performance.' if x == 'Usability' else 'Non-usability requirements are any requirements that do not discuss system usability requirements.')\n",
        "Maintainability_NFR_None_NoFunc['Label Definition'] = Maintainability_NFR_None_NoFunc['Label'].apply(lambda x: 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.' if x == 'Maintainability' else 'Non-maintainability requirements are any requirements that do not discuss system maintainability requirements.')\n",
        "\n",
        "Look_and_Feel_NFR_None_NoFunc['Label Definition'] = Look_and_Feel_NFR_None_NoFunc['Label'].apply(lambda x: 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.' if x == 'Look and Feel' else 'Non-Look and feel requirements are any requirements that do not discuss system look and feel requirements.')\n",
        "Availability_NFR_None_NoFunc['Label Definition'] = Availability_NFR_None_NoFunc['Label'].apply(lambda x: 'Availability requirements are quality requirements that ensure the maximum operational time of a system.' if x == 'Availability' else 'Non-availability requirements are any requirements that do not discuss system availability requirements.')\n",
        "Portability_NFR_None_NoFunc['Label Definition'] = Portability_NFR_None_NoFunc['Label'].apply(lambda x: 'Portability requirements define how easy it is to transport a system from its current hardware or software environment to another environment.' if x == 'Portability' else 'Non-portability requirements are any requirements that do not discuss system portability requirements.')\n",
        "\n",
        "Fault_Tolerance_NFR_None_NoFunc['Label Definition'] = Fault_Tolerance_NFR_None_NoFunc['Label'].apply(lambda x: 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.' if x == 'Fault Tolerance' else 'Non-Fault tolerance requirements are any requirements that do not discuss system fault tolerance requirements.')\n",
        "Legal_NFR_None_NoFunc['Label Definition'] = Legal_NFR_None_NoFunc['Label'].apply(lambda x: 'Legal requirements define a system legal conformity to data privacy, regulations and standards.' if x == 'Legal' else 'Non-Legal requirements are any requirements that do not discuss system legal requirements.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWj-iwA_DXQM"
      },
      "outputs": [],
      "source": [
        "##Performance\n",
        "Performance_NFR_None_NoFunc_Remove_Punctuation = Performance_NFR_None_NoFunc.copy()\n",
        "Performance_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Performance_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Performance_NFR_None_NoFunc_Add_FullStops = Performance_NFR_None_NoFunc.copy()\n",
        "Performance_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Performance_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Performance_NFR_None_NoFunc_Labels_Uppercase = Performance_NFR_None_NoFunc.copy()\n",
        "Performance_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Performance_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Performance_NFR_None_NoFunc_Labels_Lowercase = Performance_NFR_None_NoFunc.copy()\n",
        "Performance_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Performance_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Performance_NFR_None_NoFunc_Labels_Capitalized = Performance_NFR_None_NoFunc.copy()\n",
        "Performance_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Performance_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "##Security\n",
        "Security_NFR_None_NoFunc_Remove_Punctuation = Security_NFR_None_NoFunc.copy()\n",
        "Security_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Security_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Security_NFR_None_NoFunc_Add_FullStops = Security_NFR_None_NoFunc.copy()\n",
        "Security_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Security_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Security_NFR_None_NoFunc_Labels_Uppercase = Security_NFR_None_NoFunc.copy()\n",
        "Security_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Security_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Security_NFR_None_NoFunc_Labels_Lowercase = Security_NFR_None_NoFunc.copy()\n",
        "Security_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Security_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Security_NFR_None_NoFunc_Labels_Capitalized = Security_NFR_None_NoFunc.copy()\n",
        "Security_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Security_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "##Operational\n",
        "Operational_NFR_None_NoFunc_Remove_Punctuation = Operational_NFR_None_NoFunc.copy()\n",
        "Operational_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Operational_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Operational_NFR_None_NoFunc_Add_FullStops = Operational_NFR_None_NoFunc.copy()\n",
        "Operational_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Operational_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Operational_NFR_None_NoFunc_Labels_Uppercase = Operational_NFR_None_NoFunc.copy()\n",
        "Operational_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Operational_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Operational_NFR_None_NoFunc_Labels_Lowercase = Operational_NFR_None_NoFunc.copy()\n",
        "Operational_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Operational_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Operational_NFR_None_NoFunc_Labels_Capitalized = Operational_NFR_None_NoFunc.copy()\n",
        "Operational_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Operational_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "\n",
        "##Scalability\n",
        "Scalability_NFR_None_NoFunc_Remove_Punctuation = Scalability_NFR_None_NoFunc.copy()\n",
        "Scalability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Scalability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Scalability_NFR_None_NoFunc_Add_FullStops = Scalability_NFR_None_NoFunc.copy()\n",
        "Scalability_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Scalability_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Scalability_NFR_None_NoFunc_Labels_Uppercase = Scalability_NFR_None_NoFunc.copy()\n",
        "Scalability_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Scalability_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Scalability_NFR_None_NoFunc_Labels_Lowercase = Scalability_NFR_None_NoFunc.copy()\n",
        "Scalability_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Scalability_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Scalability_NFR_None_NoFunc_Labels_Capitalized = Scalability_NFR_None_NoFunc.copy()\n",
        "Scalability_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Scalability_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "##Usability\n",
        "Usability_NFR_None_NoFunc_Remove_Punctuation = Usability_NFR_None_NoFunc.copy()\n",
        "Usability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Usability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Usability_NFR_None_NoFunc_Add_FullStops = Usability_NFR_None_NoFunc.copy()\n",
        "Usability_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Usability_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Usability_NFR_None_NoFunc_Labels_Uppercase = Usability_NFR_None_NoFunc.copy()\n",
        "Usability_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Usability_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Usability_NFR_None_NoFunc_Labels_Lowercase = Usability_NFR_None_NoFunc.copy()\n",
        "Usability_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Usability_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Usability_NFR_None_NoFunc_Labels_Capitalized = Usability_NFR_None_NoFunc.copy()\n",
        "Usability_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Usability_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "## Maintainability_NFR_None_NoFunc\n",
        "Maintainability_NFR_None_NoFunc_Remove_Punctuation = Maintainability_NFR_None_NoFunc.copy()\n",
        "Maintainability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Maintainability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Maintainability_NFR_None_NoFunc_Add_FullStops = Maintainability_NFR_None_NoFunc.copy()\n",
        "Maintainability_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Maintainability_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Maintainability_NFR_None_NoFunc_Labels_Uppercase = Maintainability_NFR_None_NoFunc.copy()\n",
        "Maintainability_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Maintainability_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Maintainability_NFR_None_NoFunc_Labels_Lowercase = Maintainability_NFR_None_NoFunc.copy()\n",
        "Maintainability_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Maintainability_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Maintainability_NFR_None_NoFunc_Labels_Capitalized = Maintainability_NFR_None_NoFunc.copy()\n",
        "Maintainability_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Maintainability_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "\n",
        "## Look_and_Feel_NFR\n",
        "Look_and_Feel_NFR_None_NoFunc_Remove_Punctuation = Look_and_Feel_NFR_None_NoFunc.copy()\n",
        "Look_and_Feel_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Look_and_Feel_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Look_and_Feel_NFR_None_NoFunc_Add_FullStops = Look_and_Feel_NFR_None_NoFunc.copy()\n",
        "Look_and_Feel_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Look_and_Feel_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Look_and_Feel_NFR_None_NoFunc_Labels_Uppercase = Look_and_Feel_NFR_None_NoFunc.copy()\n",
        "Look_and_Feel_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Look_and_Feel_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Look_and_Feel_NFR_None_NoFunc_Labels_Lowercase = Look_and_Feel_NFR_None_NoFunc.copy()\n",
        "Look_and_Feel_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Look_and_Feel_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Look_and_Feel_NFR_None_NoFunc_Labels_Capitalized = Look_and_Feel_NFR_None_NoFunc.copy()\n",
        "Look_and_Feel_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Look_and_Feel_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "## Availability\n",
        "Availability_NFR_None_NoFunc_Remove_Punctuation = Availability_NFR_None_NoFunc.copy()\n",
        "Availability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Availability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Availability_NFR_None_NoFunc_Add_FullStops = Availability_NFR_None_NoFunc.copy()\n",
        "Availability_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Availability_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Availability_NFR_None_NoFunc_Labels_Uppercase = Availability_NFR_None_NoFunc.copy()\n",
        "Availability_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Availability_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Availability_NFR_None_NoFunc_Labels_Lowercase = Availability_NFR_None_NoFunc.copy()\n",
        "Availability_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Availability_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Availability_NFR_None_NoFunc_Labels_Capitalized = Availability_NFR_None_NoFunc.copy()\n",
        "Availability_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Availability_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "## Portability_NFR_None_NoFunc\n",
        "Portability_NFR_None_NoFunc_Remove_Punctuation = Portability_NFR_None_NoFunc.copy()\n",
        "Portability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Portability_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Portability_NFR_None_NoFunc_Add_FullStops = Portability_NFR_None_NoFunc.copy()\n",
        "Portability_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Portability_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Portability_NFR_None_NoFunc_Labels_Uppercase = Portability_NFR_None_NoFunc.copy()\n",
        "Portability_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Portability_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Portability_NFR_None_NoFunc_Labels_Lowercase = Portability_NFR_None_NoFunc.copy()\n",
        "Portability_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Portability_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Portability_NFR_None_NoFunc_Labels_Capitalized = Portability_NFR_None_NoFunc.copy()\n",
        "Portability_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Portability_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "##Fault_Tolerance_NFR_None_NoFunc\n",
        "Fault_Tolerance_NFR_None_NoFunc_Remove_Punctuation = Fault_Tolerance_NFR_None_NoFunc.copy()\n",
        "Fault_Tolerance_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Fault_Tolerance_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Fault_Tolerance_NFR_None_NoFunc_Add_FullStops = Fault_Tolerance_NFR_None_NoFunc.copy()\n",
        "Fault_Tolerance_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Fault_Tolerance_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Fault_Tolerance_NFR_None_NoFunc_Labels_Uppercase = Fault_Tolerance_NFR_None_NoFunc.copy()\n",
        "Fault_Tolerance_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Fault_Tolerance_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Fault_Tolerance_NFR_None_NoFunc_Labels_Lowercase = Fault_Tolerance_NFR_None_NoFunc.copy()\n",
        "Fault_Tolerance_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Fault_Tolerance_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Fault_Tolerance_NFR_None_NoFunc_Labels_Capitalized = Fault_Tolerance_NFR_None_NoFunc.copy()\n",
        "Fault_Tolerance_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Fault_Tolerance_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')\n",
        "\n",
        "##Legal\n",
        "Legal_NFR_None_NoFunc_Remove_Punctuation = Legal_NFR_None_NoFunc.copy()\n",
        "Legal_NFR_None_NoFunc_Remove_Punctuation['RequirementText'] = modify_text(Legal_NFR_None_NoFunc_Remove_Punctuation['RequirementText'],'remove_punctuation')\n",
        "\n",
        "Legal_NFR_None_NoFunc_Add_FullStops = Legal_NFR_None_NoFunc.copy()\n",
        "Legal_NFR_None_NoFunc_Add_FullStops['RequirementText'] = modify_text(Legal_NFR_None_NoFunc_Add_FullStops['RequirementText'],'add_full_stops')\n",
        "\n",
        "Legal_NFR_None_NoFunc_Labels_Uppercase = Legal_NFR_None_NoFunc.copy()\n",
        "Legal_NFR_None_NoFunc_Labels_Uppercase['Label'] = modify_labels(Legal_NFR_None_NoFunc_Labels_Uppercase['Label'],'upper')\n",
        "\n",
        "Legal_NFR_None_NoFunc_Labels_Lowercase = Legal_NFR_None_NoFunc.copy()\n",
        "Legal_NFR_None_NoFunc_Labels_Lowercase['Label'] = modify_labels(Legal_NFR_None_NoFunc_Labels_Lowercase['Label'],'lower')\n",
        "\n",
        "Legal_NFR_None_NoFunc_Labels_Capitalized = Legal_NFR_None_NoFunc.copy()\n",
        "Legal_NFR_None_NoFunc_Labels_Capitalized['Label'] = modify_labels(Legal_NFR_None_NoFunc_Labels_Capitalized['Label'],'capitalize')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg-a48lL0yNy"
      },
      "source": [
        "#### NFR grouped based on their themes (Similar)\n",
        "**Theme 1: Performance and Reliability**\n",
        "\n",
        "* Performance: The system's speed and efficiency in processing tasks.\n",
        "* Availability: The system's uptime and accessibility.\n",
        "* Fault Tolerance: The system's ability to continue functioning despite failures.\n",
        "\n",
        "**Theme 2: Usability and Experience**\n",
        "* Usability: The ease with which users can interact with the system.\n",
        "* Look and Feel: The system's visual appeal and user interface design.\n",
        "\n",
        "**Theme 3: Operational and Maintenance**\n",
        "* Maintainability: The ease of modifying and updating the system.\n",
        "* Scalability: The system's ability to handle increasing workloads.\n",
        "* (excluded) Portability: The system's ability to function in different environments.\n",
        "* Operational: The performance of a system based on its operational characteristics\n",
        "\n",
        "**Theme 4: Legal and Security**\n",
        "* Security: The system's protection against unauthorized access and data breaches.\n",
        "* Legal: Compliance with relevant laws and regulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKCqowe11bnq"
      },
      "outputs": [],
      "source": [
        "NFR_theme_1 = NFR_None_NoFunc[NFR_None_NoFunc['Label'].isin(['Performance', 'Availability', 'Fault Tolerance'])].copy()\n",
        "NFR_theme_2 = NFR_None_NoFunc[NFR_None_NoFunc['Label'].isin(['Usability', 'Look and Feel'])].copy()\n",
        "NFR_theme_3 = NFR_None_NoFunc[NFR_None_NoFunc['Label'].isin(['Maintainability', 'Scalability', 'Operational'])].copy()\n",
        "NFR_theme_4 = NFR_None_NoFunc[NFR_None_NoFunc['Label'].isin(['Security', 'Legal'])].copy()\n",
        "\n",
        "NFR_theme_1_Remove_Punctuation = NFR_Remove_Punctuation_NoFunc[NFR_Remove_Punctuation_NoFunc['Label'].isin(['Performance', 'Availability', 'Fault Tolerance'])].copy()\n",
        "NFR_theme_2_Remove_Punctuation = NFR_Remove_Punctuation_NoFunc[NFR_Remove_Punctuation_NoFunc['Label'].isin(['Usability', 'Look and Feel'])].copy()\n",
        "NFR_theme_3_Remove_Punctuation = NFR_Remove_Punctuation_NoFunc[NFR_Remove_Punctuation_NoFunc['Label'].isin(['Maintainability', 'Scalability', 'Operational'])].copy()\n",
        "NFR_theme_4_Remove_Punctuation = NFR_Remove_Punctuation_NoFunc[NFR_Remove_Punctuation_NoFunc['Label'].isin(['Security', 'Legal'])].copy()\n",
        "\n",
        "NFR_theme_1_Add_FullStops = NFR_Add_FullStops_NoFunc[NFR_Add_FullStops_NoFunc['Label'].isin(['Performance', 'Availability', 'Fault Tolerance'])].copy()\n",
        "NFR_theme_2_Add_FullStops = NFR_Add_FullStops_NoFunc[NFR_Add_FullStops_NoFunc['Label'].isin(['Usability', 'Look and Feel'])].copy()\n",
        "NFR_theme_3_Add_FullStops = NFR_Add_FullStops_NoFunc[NFR_Add_FullStops_NoFunc['Label'].isin(['Maintainability', 'Scalability', 'Operational'])].copy()\n",
        "NFR_theme_4_Add_FullStops = NFR_Add_FullStops_NoFunc[NFR_Add_FullStops_NoFunc['Label'].isin(['Security', 'Legal'])].copy()\n",
        "\n",
        "NFR_theme_1_Labels_Uppercase = NFR_Labels_Uppercase_NoFunc[NFR_Labels_Uppercase_NoFunc['Label'].isin(['PERFORMANCE', 'AVAILABILITY', 'FAULT TOLERANCE'])].copy()\n",
        "NFR_theme_2_Labels_Uppercase = NFR_Labels_Uppercase_NoFunc[NFR_Labels_Uppercase_NoFunc['Label'].isin(['USABILITY', 'LOOK AND FEEL'])].copy()\n",
        "NFR_theme_3_Labels_Uppercase = NFR_Labels_Uppercase_NoFunc[NFR_Labels_Uppercase_NoFunc['Label'].isin(['MAINTAINABILITY', 'SCALABILITY', 'OPERATIONAL'])].copy()\n",
        "NFR_theme_4_Labels_Uppercase = NFR_Labels_Uppercase_NoFunc[NFR_Labels_Uppercase_NoFunc['Label'].isin(['SECURITY', 'LEGAL'])].copy()\n",
        "\n",
        "NFR_theme_1_Labels_Lowercase = NFR_Labels_Lowercase_NoFunc[NFR_Labels_Lowercase_NoFunc['Label'].isin(['performance', 'availability', 'fault tolerance'])].copy()\n",
        "NFR_theme_2_Labels_Lowercase = NFR_Labels_Lowercase_NoFunc[NFR_Labels_Lowercase_NoFunc['Label'].isin(['usability', 'look and feel'])].copy()\n",
        "NFR_theme_3_Labels_Lowercase = NFR_Labels_Lowercase_NoFunc[NFR_Labels_Lowercase_NoFunc['Label'].isin(['maintainability', 'scalability', 'operational'])].copy()\n",
        "NFR_theme_4_Labels_Lowercase = NFR_Labels_Lowercase_NoFunc[NFR_Labels_Lowercase_NoFunc['Label'].isin(['security', 'legal'])].copy()\n",
        "\n",
        "NFR_theme_1_Labels_Capitalized = NFR_Labels_Capitalized_NoFunc[NFR_Labels_Capitalized_NoFunc['Label'].isin(['Performance', 'Availability', 'Fault Tolerance'])].copy()\n",
        "NFR_theme_2_Labels_Capitalized = NFR_Labels_Capitalized_NoFunc[NFR_Labels_Capitalized_NoFunc['Label'].isin(['Usability', 'Look and Feel'])].copy()\n",
        "NFR_theme_3_Labels_Capitalized = NFR_Labels_Capitalized_NoFunc[NFR_Labels_Capitalized_NoFunc['Label'].isin(['Maintainability', 'Scalability', 'Operational'])].copy()\n",
        "NFR_theme_4_Labels_Capitalized = NFR_Labels_Capitalized_NoFunc[NFR_Labels_Capitalized_NoFunc['Label'].isin(['Security', 'Legal'])].copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top 4 NFR Classes ONLY"
      ],
      "metadata": {
        "id": "8nBLIfM7jlnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NFR_top = NFR_None_NoFunc[NFR_None_NoFunc['Label'].isin(['Performance', 'Usability', 'Security', 'Operational'])].copy()\n",
        "NFR_top_Remove_Punctuation = NFR_Remove_Punctuation_NoFunc[NFR_Remove_Punctuation_NoFunc['Label'].isin(['Performance', 'Usability', 'Security', 'Operational'])].copy()\n",
        "NFR_top_Add_FullStops = NFR_Add_FullStops_NoFunc[NFR_Add_FullStops_NoFunc['Label'].isin(['Performance', 'Usability', 'Security', 'Operational'])].copy()\n",
        "NFR_top_Labels_Uppercase = NFR_Labels_Uppercase_NoFunc[NFR_Labels_Uppercase_NoFunc['Label'].isin(['PERFORMANCE', 'USABILITY', 'SECURITY', 'OPERATIONAL'])].copy()\n",
        "NFR_top_Labels_Lowercase = NFR_Labels_Lowercase_NoFunc[NFR_Labels_Lowercase_NoFunc['Label'].isin(['performance', 'usability', 'security', 'operational'])].copy()\n",
        "NFR_top_Labels_Capitalized = NFR_Labels_Capitalized_NoFunc[NFR_Labels_Capitalized_NoFunc['Label'].isin(['Performance', 'Usability', 'Security', 'Operational'])].copy()"
      ],
      "metadata": {
        "id": "i5b1-6R4jpkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii8j_LNFNo6h"
      },
      "source": [
        "#LLMs (Models and Tokenizers)\n",
        "\n",
        "In this cell, we recalled the models and tokenizers from the Hugging Face Models Hub in advance to avoid reloading each model every time we classify requirements. We saved these model and tokenizer instances into a list for later retrieval.\n",
        "\n",
        "It is notworthy that we used AutoModelForSequenceClassification. This class is a general-purpose class that can be used with any pre-trained model from the Hugging Face Transformers library that supports sequence classification. It automatically detects the correct model architecture based on the provided model name or path. However, there special classes for seq. classification for some the used models, and we noticed the performance is the same, in both general and special classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RKlf1apOejk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a0fb10-5e2a-4e5f-cbb7-958f0bb05df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AoDNs0zXvBS"
      },
      "outputs": [],
      "source": [
        "  #llms_shortnames = [\"Bloom\", \"T5\", \"Gemma\", \"Llama\", \"BART\"]\n",
        "  #model_names = [\"bigscience/bloom-560m\", \"facebook/tart-full-flan-t5-xl\", \"google/gemma-2b\", \"meta-llama/Meta-Llama-3-8B\", \"facebook/bart-large-mnli\"]\n",
        "  #\"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "  #In this notebook, we used Llama as a running example!\n",
        "  llms_shortnames = [\"Llama\"]\n",
        "  model_names = [\"meta-llama/Meta-Llama-3-8B\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLcq0o7iA5Ar"
      },
      "source": [
        "#Generate Definitions Using LLM (Optional)\n",
        "\n",
        "This step assesses the model's comprehension of predefined labels assigned to the experimental datasets. By employing the '`generate`' method, we prompt the model to construct a definition for a given label, thereby evaluating its ability to articulate its understanding.\n",
        "\n",
        "In this we used two prompts:\n",
        "\n",
        "Prompt 1: `\"Define {label} as a software requirement:\"`\n",
        "\n",
        "Prompt 2: `\"Define the following software requirement label: {label}\"`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #llms_shortnames = [\"Bloom\", \"T5\", \"Gemma\", \"Llama\", \"BART\"]\n",
        "  #model_names = [\"bigscience/bloom-560m\", \"facebook/tart-full-flan-t5-xl\", \"google/gemma-2b\", \"meta-llama/Meta-Llama-3-8B\", \"facebook/bart-large-mnli\"]\n",
        "  llms_shortnames = [\"Llama\"]\n",
        "  model_names = [\"meta-llama/Meta-Llama-3-8B\"]"
      ],
      "metadata": {
        "id": "3BXcjEcJ8DUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx9wUs9leWI0"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "labels = ['Functional', 'Non-functional', 'Quality', 'Non-quality', 'Security', 'Non-Security',\n",
        "          'Performance', 'Security', 'Operational', 'Scalability', 'Usability', 'Maintainability',\n",
        "          'Reliability', 'Look and Feel', 'Availability', 'Portability', 'Legal', 'Fault Tolerance']\n",
        "\n",
        "with tf.device(device_name):\n",
        "  def generate_text(model, tokenizer, prompt, max_new_tokens=50):\n",
        "    # Tokenize the input\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
        "    output = model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=max_new_tokens)\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "  # Example usage:\n",
        "  tokenizer = transformers.AutoTokenizer.from_pretrained(model_names[0])\n",
        "  model_ = transformers.AutoModelForCausalLM.from_pretrained(model_names[0])\n",
        "\n",
        "'''\n",
        "  for label in labels:\n",
        "    prompt = f\"In requirements engineering, define the nonfunctional requirements class {label}\"\n",
        "    generated_definition = generate_text(model_, tokenizer, prompt)\n",
        "    print(generated_definition)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save each generated defintion as label, defntion, model name\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'generated_definition' is the variable containing the generated definition.\n",
        "\n",
        "# Create an empty list to store the data\n",
        "data = []\n",
        "\n",
        "# Iterate over the labels and generated definitions\n",
        "for label in labels:\n",
        "  prompt = f\"In Requirements Engineering (RE), the requirements class {label} is about  \"\n",
        "  generated_definition = generate_text(model_, tokenizer, prompt)\n",
        "  print(generated_definition)\n",
        "  data.append([label, generated_definition, model_names[0]])  # Assuming model_names[0] is the model name\n",
        "\n",
        "df_2 = pd.DataFrame()\n",
        "# Create a pandas DataFrame from the data\n",
        "df_2 = pd.DataFrame(data, columns=['label', 'definition', 'model_name'])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_2.to_csv('generated_definitions_def2_llama_3.csv', index=False)\n"
      ],
      "metadata": {
        "id": "mTZXbtYOIHG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the labels and generated definitions\n",
        "for label in labels:\n",
        "  prompt = f\"The requirements class {label} is defined as  \"\n",
        "  generated_definition = generate_text(model_, tokenizer, prompt)\n",
        "  print(generated_definition)\n",
        "  data.append([label, generated_definition, model_names[0]])  # Assuming model_names[0] is the model name\n",
        "\n",
        "df_1 = pd.DataFrame()\n",
        "# Create a pandas DataFrame from the data\n",
        "df_1 = pd.DataFrame(data, columns=['label', 'definition', 'model_name'])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_1.to_csv('generated_definitions_def1_llama_3.csv', index=False)"
      ],
      "metadata": {
        "id": "tT_3jOJJI3AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: download all files except sample_data\n",
        "\n",
        "!zip -r /content/downloaded_defintions_files_Friday.zip * -x \"sample_data/*\"\n"
      ],
      "metadata": {
        "id": "nOAQ7LtVeEZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6jDxZzBBkJK"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "labels = ['Functional', 'Non-functional', 'Quality', 'Non-quality', 'Security', 'Non-Security',\n",
        "          'Performance', 'Security', 'Operational', 'Scalability', 'Usability', 'Maintainability',\n",
        "          'Reliability', 'Look and Feel', 'Availability', 'Portability', 'Legal', 'Fault Tolerance', 'Functionality']\n",
        "\n",
        "with tf.device(device_name):\n",
        "  def generate_definitions(labels, model, tokenizer):\n",
        "    for label in labels:\n",
        "      prompt = f\"Define the nonfunctional requirements class {label}\"\n",
        "      inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "      outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "      definition = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "      print(f\"Definition of '{label}': {definition}\")\n",
        "\n",
        "  tokenizer = transformers.AutoTokenizer.from_pretrained(model_names[0])\n",
        "  model_ = transformers.AutoModelForCausalLM.from_pretrained(model_names[0])\n",
        "  generate_definitions(labels, model_, tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zahO4aMlo-Yj"
      },
      "source": [
        "#ZSL Classification\n",
        "For ZSL classification, we followed inference-based or as it's called entailment-based Zero-Shot Learning (ZSL) which focuses on determining whether a given piece of text logically implies or supports a specific class or concept.\n",
        "For example, if the class is \"animal\", and the text is \"the cat chased the mouse,\" the model should determine that the text entails the class \"animal\" because a cat is an animal.\n",
        "\n",
        "We experimented ZSL with two programming methods: one withusing torch library as we implemented a basic entailment process using PyTorch, where we computed model outputs and extracted logits for subsequent classification, and the other using HF pipeline (classifier). The latter method, i.e., HF pipeline, is used as a 'sanity check' or to verify the results we got from our code is similar to the results obtained from the pipeline. Some blogs/posts refer to different accurcies and predication scores [link](https://discuss.huggingface.co/t/new-pipeline-for-zero-shot-text-classification/681/104)\n",
        "\n",
        "\n",
        "\n",
        "> We prevosily experimented one of the funadmental appraoches for ZSL which is called \"embedding-based\" approach. *Reference: Alhoshan, W., Ferrari, A., & Zhao, L. (2023). Zero-shot learning for requirements classification: An exploratory study. Information and Software Technology, 159, 107202.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP10JEj9nHsG"
      },
      "source": [
        "## ZSL (Inference-based) - Torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK6lkJHVA9bv"
      },
      "outputs": [],
      "source": [
        "# Delete all files from colab -- for new experiments\n",
        "\n",
        "!rm -rf *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfTlwZK_JF_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c5f83f-5e66-428d-ee38-07e2c60069ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================>>Classifying and evaluating using Model: Llama and Dataset: NFR-Multi-Remove_Punctuation<<====================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.06467321330301426, Recall: 0.08672086720867209, F1-Score: 0.06068336643442537\n",
            "Total execution time: 00:02:16\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.08629523395606672, Recall: 0.11924119241192412, F1-Score: 0.07234966929349168\n",
            "Total execution time: 00:02:07\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.024116760471058776, Recall: 0.08401084010840108, F1-Score: 0.03664992493693571\n",
            "Total execution time: 00:02:01\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.0036803554798226085, Recall: 0.03523035230352303, F1-Score: 0.006481831391847065\n",
            "Total execution time: 00:02:04\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.17396203971222451, Recall: 0.08401084010840108, F1-Score: 0.052790645498391256\n",
            "Total execution time: 00:03:53\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.23272158248937885, Recall: 0.16531165311653118, F1-Score: 0.11607767156753138\n",
            "Total execution time: 00:03:53\n",
            "====================>>Classifying and evaluating using Model: Llama and Dataset: NFR-Multi-Add_FullStops<<====================\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.0941669892889405, Recall: 0.08130081300813008, F1-Score: 0.06512816187281192\n",
            "Total execution time: 00:02:13\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.046229387690012815, Recall: 0.10298102981029811, F1-Score: 0.05801492898987303\n",
            "Total execution time: 00:02:13\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.06658908330611331, Recall: 0.1002710027100271, F1-Score: 0.07108864863968087\n",
            "Total execution time: 00:02:06\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.041466890937921656, Recall: 0.05962059620596206, F1-Score: 0.03239087831785407\n",
            "Total execution time: 00:02:10\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.15252745290239136, Recall: 0.12737127371273713, F1-Score: 0.12085372597385047\n",
            "Total execution time: 00:03:58\n",
            "['Performance', 'Look and Feel', 'Usability', 'Availability', 'Security', 'Fault Tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.0835885517079854, Recall: 0.0948509485094851, F1-Score: 0.05796149621683914\n",
            "Total execution time: 00:03:58\n",
            "====================>>Classifying and evaluating using Model: Llama and Dataset: NFR-Multi-Labels_Capitalized<<====================\n",
            "['Performance', 'Look and feel', 'Usability', 'Availability', 'Security', 'Fault tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.26940868906475923, Recall: 0.06775067750677506, F1-Score: 0.0437329465157152\n",
            "Total execution time: 00:02:10\n",
            "['Performance', 'Look and feel', 'Usability', 'Availability', 'Security', 'Fault tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.10913620554254498, Recall: 0.12195121951219512, F1-Score: 0.08962173966371562\n",
            "Total execution time: 00:02:10\n",
            "['Performance', 'Look and feel', 'Usability', 'Availability', 'Security', 'Fault tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.03544676370629485, Recall: 0.08401084010840108, F1-Score: 0.04441856685419624\n",
            "Total execution time: 00:02:03\n",
            "['Performance', 'Look and feel', 'Usability', 'Availability', 'Security', 'Fault tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.02006323396567299, Recall: 0.04878048780487805, F1-Score: 0.013233104928072508\n",
            "Total execution time: 00:02:06\n",
            "['Performance', 'Look and feel', 'Usability', 'Availability', 'Security', 'Fault tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.15753920175924457, Recall: 0.15176151761517614, F1-Score: 0.12174671225023677\n",
            "Total execution time: 00:03:55\n",
            "['Performance', 'Look and feel', 'Usability', 'Availability', 'Security', 'Fault tolerance', 'Scalability', 'Operational', 'Legal', 'Maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.13810165200875565, Recall: 0.13279132791327913, F1-Score: 0.07257887976523443\n",
            "Total execution time: 00:03:55\n",
            "====================>>Classifying and evaluating using Model: Llama and Dataset: NFR-Multi-Labels_Lowercase<<====================\n",
            "['performance', 'look and feel', 'usability', 'availability', 'security', 'fault tolerance', 'scalability', 'operational', 'legal', 'maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.032889560225292595, Recall: 0.05420054200542006, F1-Score: 0.018443198008119922\n",
            "Total execution time: 00:02:10\n",
            "['performance', 'look and feel', 'usability', 'availability', 'security', 'fault tolerance', 'scalability', 'operational', 'legal', 'maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.06466887693270379, Recall: 0.12195121951219512, F1-Score: 0.07457845205889344\n",
            "Total execution time: 00:02:10\n",
            "['performance', 'look and feel', 'usability', 'availability', 'security', 'fault tolerance', 'scalability', 'operational', 'legal', 'maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.15119289848937031, Recall: 0.06233062330623306, F1-Score: 0.05109648374368792\n",
            "Total execution time: 00:02:03\n",
            "['performance', 'look and feel', 'usability', 'availability', 'security', 'fault tolerance', 'scalability', 'operational', 'legal', 'maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.16185105478505765, Recall: 0.04607046070460705, F1-Score: 0.03490879902209964\n",
            "Total execution time: 00:02:07\n",
            "['performance', 'look and feel', 'usability', 'availability', 'security', 'fault tolerance', 'scalability', 'operational', 'legal', 'maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.20560465501531464, Recall: 0.24932249322493225, F1-Score: 0.20943511128663872\n",
            "Total execution time: 00:03:55\n",
            "['performance', 'look and feel', 'usability', 'availability', 'security', 'fault tolerance', 'scalability', 'operational', 'legal', 'maintainability']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.15754281391041855, Recall: 0.1842818428184282, F1-Score: 0.10293207022558559\n",
            "Total execution time: 00:03:55\n",
            "====================>>Classifying and evaluating using Model: Llama and Dataset: NFR-Multi-Labels_Uppercase<<====================\n",
            "['PERFORMANCE', 'LOOK AND FEEL', 'USABILITY', 'AVAILABILITY', 'SECURITY', 'FAULT TOLERANCE', 'SCALABILITY', 'OPERATIONAL', 'LEGAL', 'MAINTAINABILITY']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.05565883201790895, Recall: 0.06775067750677506, F1-Score: 0.05226915358536821\n",
            "Total execution time: 00:02:13\n",
            "['PERFORMANCE', 'LOOK AND FEEL', 'USABILITY', 'AVAILABILITY', 'SECURITY', 'FAULT TOLERANCE', 'SCALABILITY', 'OPERATIONAL', 'LEGAL', 'MAINTAINABILITY']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.08395899438273403, Recall: 0.15989159891598917, F1-Score: 0.09828969402156675\n",
            "Total execution time: 00:02:13\n",
            "['PERFORMANCE', 'LOOK AND FEEL', 'USABILITY', 'AVAILABILITY', 'SECURITY', 'FAULT TOLERANCE', 'SCALABILITY', 'OPERATIONAL', 'LEGAL', 'MAINTAINABILITY']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.061630213800228144, Recall: 0.04878048780487805, F1-Score: 0.03867413368292591\n",
            "Total execution time: 00:02:10\n",
            "['PERFORMANCE', 'LOOK AND FEEL', 'USABILITY', 'AVAILABILITY', 'SECURITY', 'FAULT TOLERANCE', 'SCALABILITY', 'OPERATIONAL', 'LEGAL', 'MAINTAINABILITY']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.04294989210153579, Recall: 0.056910569105691054, F1-Score: 0.043644420290805716\n",
            "Total execution time: 00:02:13\n",
            "['PERFORMANCE', 'LOOK AND FEEL', 'USABILITY', 'AVAILABILITY', 'SECURITY', 'FAULT TOLERANCE', 'SCALABILITY', 'OPERATIONAL', 'LEGAL', 'MAINTAINABILITY']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.1240228515838272, Recall: 0.1978319783197832, F1-Score: 0.13801162257852473\n",
            "Total execution time: 00:03:58\n",
            "['PERFORMANCE', 'LOOK AND FEEL', 'USABILITY', 'AVAILABILITY', 'SECURITY', 'FAULT TOLERANCE', 'SCALABILITY', 'OPERATIONAL', 'LEGAL', 'MAINTAINABILITY']\n",
            "['Performance requirements are quality requirements that specify the performance measure of the system.', 'Look and feel requirements are quality requirements that consider all static and dynamic aspects of the user interface, including colors, shapes, layout, typefaces, buttons, boxes, and menus.', 'Usability requirements are quality requirements that define what a system has to do to support users task performance.', 'Availability requirements are quality requirements that ensure the maximum operational time of a system.', 'Security requirements are quality requirements that ensure the integrity, confidentiality, reliability, availability, and safety of a system.', 'Fault tolerance requirements are quality requirements that ensure the system to have the ability to detect the fault and to have a backup plan.', 'Scalability requirements define the capability of a system to expand and adapt to the changing size and needs of the client.', 'Operational requirements define the specific conditions and situations under which the system will function.', 'Legal requirements define a system legal conformity to data privacy, regulations and standards.', 'Maintainability requirements are quality requirements that define how easy it is to maintain and evolve a system over time.']\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n",
            "Multi-classification with softmax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 136.098 s\n",
            "File: <ipython-input-73-6be0b9da56ff>\n",
            "Function: classify_and_evaluate_torch at line 8\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     8                                             def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
            "     9                                               # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
            "    10         1   12697646.0    1e+07      0.0      model.eval()\n",
            "    11         1 8303579579.0    8e+09      6.1      model.to(device)\n",
            "    12                                               # Add a padding token to the tokenizer\n",
            "    13         1      95819.0  95819.0      0.0      tokenizer.pad_token = tokenizer.eos_token\n",
            "    14                                               # Add padding token to the model config\n",
            "    15         1      51850.0  51850.0      0.0      model.config.pad_token_id = tokenizer.pad_token_id\n",
            "    16         1    6323145.0    6e+06      0.0      torch.cuda.empty_cache()\n",
            "    17         1    1248823.0    1e+06      0.0      candidate_labels = df['Label'].unique().tolist()\n",
            "    18         1     173529.0 173529.0      0.0      print(candidate_labels)\n",
            "    19         1    1355219.0    1e+06      0.0      definitions = df['Label Definition'].unique().tolist()\n",
            "    20         1     526484.0 526484.0      0.0      print(definitions)\n",
            "    21         1       1462.0   1462.0      0.0      results = []\n",
            "    22         1       1144.0   1144.0      0.0      true_labels = []\n",
            "    23         1       1221.0   1221.0      0.0      predicted_labels = []\n",
            "    24       370  166276502.0 449396.0      0.1      for _, row in df.iterrows():\n",
            "    25       369   19059304.0  51651.2      0.0          req = row['RequirementText']\n",
            "    26       369    4863895.0  13181.3      0.0          true_label = row['Label']\n",
            "    27                                                   # Create input pairs (template or prompt)\n",
            "    28       369     124386.0    337.1      0.0          match prompt_no:\n",
            "    29       369     168447.0    456.5      0.0            case 1:\n",
            "    30       369   11115769.0  30124.0      0.0              input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
            "    31                                                     case 2:\n",
            "    32                                                       input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
            "    33                                                     case 3:\n",
            "    34                                                       input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
            "    35                                                     case 4:\n",
            "    36                                                       input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
            "    37                                                     case 5:\n",
            "    38                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    39                                                     case 6:\n",
            "    40                                                       input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
            "    41                                           \n",
            "    42                                                   # Tokenize input pairs\n",
            "    43       369  985470093.0    3e+06      0.7          encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
            "    44                                                   #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
            "    45                                                   # Method 1\n",
            "    46                                                   # Run through the model\n",
            "    47       738   20925048.0  28353.7      0.0          with torch.no_grad():\n",
            "    48       369        3e+10    8e+07     22.4            output = model(**encoded_input)\n",
            "    49       369    1389966.0   3766.8      0.0            logits = output.logits\n",
            "    50                                                   # Calculate probabilities for all classes\n",
            "    51       369     599817.0   1625.5      0.0          if(len(candidate_labels)>2):\n",
            "    52       369   98907855.0 268043.0      0.1            print(\"Multi-classification with softmax\")\n",
            "    53       369  327968700.0 888804.1      0.2            log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
            "    54       369   16211663.0  43934.0      0.0            all_probs = torch.exp(log_probs)\n",
            "    55                                                   else:\n",
            "    56                                                     print(\"Binary-classification with sigmoid\")\n",
            "    57                                                     all_probs = torch.sigmoid(logits)\n",
            "    58       369        1e+11    3e+08     70.2          props = all_probs.tolist()\n",
            "    59                                                   # Find the index of the list with the highest prop (1st element)\n",
            "    60       369    9512170.0  25778.2      0.0          max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
            "    61                                                   # Extract the first element of the list with the highest first element\n",
            "    62       369     209854.0    568.7      0.0          result = props[max_index][0]\n",
            "    63       369     684915.0   1856.1      0.0          predicted_label = candidate_labels[max_index]\n",
            "    64                                                   # Append results to the list\n",
            "    65       738    6589227.0   8928.5      0.0          results.append({\n",
            "    66       369     330593.0    895.9      0.0              \"LLM\": llm_name,\n",
            "    67       369     178480.0    483.7      0.0              \"Dataset_Type_Variation\": dataset_name,\n",
            "    68       369     272606.0    738.8      0.0              \"Requirement\": req,\n",
            "    69       369     200994.0    544.7      0.0              \"Labels\": candidate_labels,\n",
            "    70       369     166249.0    450.5      0.0              \"True Label\": true_label,\n",
            "    71       369     142566.0    386.4      0.0              \"Predicted Label\": predicted_label,\n",
            "    72                                                       #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
            "    73       369   40208385.0 108965.8      0.0              \"Scores\":  all_probs.tolist()\n",
            "    74                                                   })\n",
            "    75       369     716287.0   1941.2      0.0          true_labels.append(true_label)\n",
            "    76       369     827327.0   2242.1      0.0          predicted_labels.append(predicted_label)\n",
            "    77                                           \n",
            "    78         1   14614483.0    1e+07      0.0      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
            "    79         1       8380.0   8380.0      0.0      return results, precision, recall, f1\n",
            "\n",
            "Precision: 0.09916877862282482, Recall: 0.2140921409214092, F1-Score: 0.11753296255378351\n",
            "Total execution time: 00:03:58\n"
          ]
        }
      ],
      "source": [
        "from line_profiler import LineProfiler\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "with tf.device(device_name):\n",
        "  from sklearn.metrics import precision_recall_fscore_support\n",
        "  import csv\n",
        "  def classify_and_evaluate_torch(df, model, tokenizer, llm_name, dataset_name, prompt_no = 1):\n",
        "    # Assuming 'device' is defined elsewhere as 'cuda' or 'cpu'\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    # Add a padding token to the tokenizer\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    # Add padding token to the model config\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "    torch.cuda.empty_cache()\n",
        "    candidate_labels = df['Label'].unique().tolist()\n",
        "    print(candidate_labels)\n",
        "    definitions = df['Label Definition'].unique().tolist()\n",
        "    print(definitions)\n",
        "    results = []\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    for _, row in df.iterrows():\n",
        "        req = row['RequirementText']\n",
        "        true_label = row['Label']\n",
        "        # Create input pairs (template or prompt)\n",
        "        match prompt_no:\n",
        "          case 1:\n",
        "            input_texts = [f\"This requirement: '{req}' is about '{label}' requirement.\" for label in candidate_labels]\n",
        "          case 2:\n",
        "            input_texts = [f\"This requirement: '{req}' belongs to '{label}' category.\" for label in candidate_labels]\n",
        "          case 3:\n",
        "            input_texts = [f\"Is this requirement: '{req}' about {label} requirement?\" for label in candidate_labels]\n",
        "          case 4:\n",
        "            input_texts = [f\"Does this requirement: '{req}' belong to {label} category?\" for label in candidate_labels]\n",
        "          case 5:\n",
        "            input_texts = [f\"{definition}. Hence this requirement: '{req}' is about  {label} requirement.\" for label,definition in zip(candidate_labels,definitions)]\n",
        "          case 6:\n",
        "            input_texts = [f\"{definition}. Hence this requirement: '{req}' belongs to  {label} category.\" for label,definition in zip(candidate_labels,definitions)]\n",
        "\n",
        "        # Tokenize input pairs\n",
        "        encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "        #encoded_input = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
        "        # Method 1\n",
        "        # Run through the model\n",
        "        with torch.no_grad():\n",
        "          output = model(**encoded_input)\n",
        "          logits = output.logits\n",
        "        # Calculate probabilities for all classes\n",
        "        if(len(candidate_labels)>2):\n",
        "          print(\"Multi-classification with softmax\")\n",
        "          log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
        "          all_probs = torch.exp(log_probs)\n",
        "        else:\n",
        "          print(\"Binary-classification with sigmoid\")\n",
        "          all_probs = torch.sigmoid(logits)\n",
        "        props = all_probs.tolist()\n",
        "        # Find the index of the list with the highest prop (1st element)\n",
        "        max_index = max(range(len(props)), key=lambda i: props[i][0])\n",
        "        # Extract the first element of the list with the highest first element\n",
        "        result = props[max_index][0]\n",
        "        predicted_label = candidate_labels[max_index]\n",
        "        # Append results to the list\n",
        "        results.append({\n",
        "            \"LLM\": llm_name,\n",
        "            \"Dataset_Type_Variation\": dataset_name,\n",
        "            \"Requirement\": req,\n",
        "            \"Labels\": candidate_labels,\n",
        "            \"True Label\": true_label,\n",
        "            \"Predicted Label\": predicted_label,\n",
        "            #\"Scores\": entailment_probs.tolist() if entailment_probs is not None else None\n",
        "            \"Scores\":  all_probs.tolist()\n",
        "        })\n",
        "        true_labels.append(true_label)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
        "    return results, precision, recall, f1\n",
        "\n",
        "  profiler = LineProfiler()\n",
        "  profiler.add_function(classify_and_evaluate_torch)\n",
        "  profiler.enable_by_count()\n",
        "\n",
        "  dataset_title = \"NFR-multi-classification\"\n",
        "  datasets = [NFR_Remove_Punctuation_NoFunc, NFR_Add_FullStops_NoFunc, NFR_Labels_Capitalized_NoFunc, NFR_Labels_Lowercase_NoFunc, NFR_Labels_Uppercase_NoFunc]\n",
        "  dataset_names = ['NFR-Multi-Remove_Punctuation', 'NFR-Multi-Add_FullStops', 'NFR-Multi-Labels_Capitalized', 'NFR-Multi-Labels_Lowercase', 'NFR-Multi-Labels_Uppercase']\n",
        "  '''\n",
        "  dataset_title = \"NFR-Thematic-fixing-theme-3\"\n",
        "  datasets = [NFR_theme_3, NFR_theme_3_Remove_Punctuation, NFR_theme_3_Add_FullStops, NFR_theme_3_Labels_Uppercase, NFR_theme_3_Labels_Lowercase, NFR_theme_3_Labels_Capitalized]\n",
        "  dataset_names = ['NFR-Operational-Maintenance', 'NFR-Operational-Maintenance-Remove_Punctuation', 'NFR-Operational-Maintenance-Add_FullStops', 'NFR-Operational-Maintenance-Labels_Uppercase', 'NFR-Operational-Maintenance-Labels_Lowercase', 'NFR-Operational-Maintenance-Labels_Capitalized']\n",
        "\n",
        "\n",
        "  dataset_title = \"NFR-Top-Four\"\n",
        "  datasets = [NFR_top, NFR_top_Remove_Punctuation, NFR_top_Add_FullStops, NFR_top_Labels_Uppercase, NFR_top_Labels_Lowercase, NFR_top_Labels_Capitalized]\n",
        "  dataset_names = [\"NFR-Top-None\", \"NFR-TOP_Remove_Punctuation\", \"NFR-TOP_Add_FullStops\", \"NFR-TOP_Labels_Uppercase\", \"NFR-TOP_Labels_Lowercase\", \"NFR-TOP_Labels_Capitalized\"]\n",
        "\n",
        "\n",
        "  dataset_title = \"NFR-Thematic\"\n",
        "  datasets = [NFR_theme_1, NFR_theme_1_Remove_Punctuation, NFR_theme_1_Add_FullStops, NFR_theme_1_Labels_Uppercase, NFR_theme_1_Labels_Lowercase, NFR_theme_1_Labels_Capitalized,\n",
        "              NFR_theme_2, NFR_theme_2_Remove_Punctuation, NFR_theme_2_Add_FullStops, NFR_theme_2_Labels_Uppercase, NFR_theme_2_Labels_Lowercase, NFR_theme_2_Labels_Capitalized,\n",
        "              NFR_theme_3, NFR_theme_3_Remove_Punctuation, NFR_theme_3_Add_FullStops, NFR_theme_3_Labels_Uppercase, NFR_theme_3_Labels_Lowercase, NFR_theme_3_Labels_Capitalized,\n",
        "              NFR_theme_4, NFR_theme_4_Remove_Punctuation, NFR_theme_4_Add_FullStops, NFR_theme_4_Labels_Uppercase, NFR_theme_4_Labels_Lowercase, NFR_theme_4_Labels_Capitalized]\n",
        "\n",
        "  dataset_names = ['NFR-Performance-Reliability', 'NFR-Performance-Reliability-Remove_Punctuation', 'NFR-Performance-Reliability-Add_FullStops', 'NFR-Performance-Reliability-Labels_Uppercase', 'NFR-Performance-Reliability-Labels_Lowercase', 'NFR-Performance-Reliability-Labels_Capitalized',\n",
        "              'NFR-Usability-Experience', 'NFR-Usability-Experience-Remove_Punctuation', 'NFR-Usability-Experience-Add_FullStops', 'NFR-Usability-Experience-Labels_Uppercase', 'NFR-Usability-Experience-Labels_Lowercase', 'NFR-Usability-Experience-Labels_Capitalized',\n",
        "              'NFR-Operational-Maintenance', 'NFR-Operational-Maintenance-Remove_Punctuation', 'NFR-Operational-Maintenance-Add_FullStops', 'NFR-Operational-Maintenance-Labels_Uppercase', 'NFR-Operational-Maintenance-Labels_Lowercase', 'NFR-Operational-Maintenance-Labels_Capitalized',\n",
        "              'NFR-Legal-Security', 'NFR-Legal-Security-Remove_Punctuation', 'NFR-Legal-Security-Add_FullStops', 'NFR-Legal-Security-Labels_Uppercase', 'NFR-Legal-Security-Labels_Lowercase', 'NFR-Legal-Security-Labels_Capitalized']\n",
        "  '''\n",
        "\n",
        "  llm_name =  llms_shortnames[0]\n",
        "  for j, (model, tokenizer) in enumerate(models_and_tokenizers):\n",
        "      for i, dataset in enumerate(datasets):\n",
        "          # Classify and evaluate for each dataset and model\n",
        "          all_results = []\n",
        "          evaluation_metrics = []\n",
        "          dataset_name = dataset_names[i]\n",
        "          print(f\"====================>>Classifying and evaluating using Model: {llms_shortnames[j]} and Dataset: {dataset_names[i]}<<====================\")\n",
        "          llm_name = llms_shortnames[j]\n",
        "          for prompt_no in range(1,7):\n",
        "            start_time = time.time()\n",
        "            results, precision, recall, f1 = classify_and_evaluate_torch(dataset, model, tokenizer, llm_name, dataset_name, prompt_no)\n",
        "            profiler.disable_by_count()\n",
        "            profiler.print_stats()\n",
        "            print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
        "            end_time = time.time()\n",
        "            elapsed_time = end_time - start_time\n",
        "            # Format elapsed time as HH:MM:SS\n",
        "            hours = int(elapsed_time // 3600)\n",
        "            minutes = int((elapsed_time % 3600) // 60)\n",
        "            seconds = int(elapsed_time % 60)\n",
        "            time_string = f\"Total execution time: {hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "            print(time_string)\n",
        "            match prompt_no:\n",
        "              case 1:\n",
        "                prompt_title = \"Asseration-'is about'\"\n",
        "              case 2:\n",
        "                prompt_title = \"Asseration-'belongs to'\"\n",
        "              case 3:\n",
        "                prompt_title = \"Question-'is about'\"\n",
        "              case 4:\n",
        "                prompt_title = \"Question-'belongs to'\"\n",
        "              case 5:\n",
        "                prompt_title = \"Definition-'is about'\"\n",
        "              case 6:\n",
        "                prompt_title = \"Definition-'belongs to'\"\n",
        "            evaluation_metrics.append({\n",
        "              \"Prompt\": prompt_title,\n",
        "              \"LLM\": llm_name,\n",
        "              \"Dataset_Type_Variation\": dataset_name,\n",
        "              \"Precision\": precision,\n",
        "              \"Recall\": recall,\n",
        "              \"F1-Score\": f1,\n",
        "              \"Execution Time\": time_string,\n",
        "            })\n",
        "            all_results.extend(results)\n",
        "            # Save classification results to CSV\n",
        "          with open(dataset_title+'_'+dataset_name+'_'+ llm_name+'_ZSL_Torch_classification_results_Template.csv', 'w', newline='') as csvfile:\n",
        "            fieldnames = [\"LLM\", \"Dataset_Type_Variation\", \"Requirement\", \"Labels\", \"True Label\", \"Predicted Label\", \"Scores\"]\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            writer.writerows(all_results)\n",
        "            # Save evaluation metrics to CSV\n",
        "          with open(dataset_title+'_'+dataset_name+'_'+llm_name+'_ZSL_Torch_evaluation_metrics_Template.csv', 'w', newline='') as csvfile:\n",
        "            fieldnames = [\"Prompt\", \"LLM\", \"Dataset_Type_Variation\", \"Precision\", \"Recall\", \"F1-Score\", \"Execution Time\"]\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            writer.writerows(evaluation_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS1pODBX3Bi0"
      },
      "outputs": [],
      "source": [
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb8YftAnpPVX"
      },
      "source": [
        "##ZSL (Inference-based) - HF Pipeline (Not-used)\n",
        "\n",
        "\n",
        "reference: https://github.com/huggingface/transformers/blob/main/src/transformers/pipelines/text_classification.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B94lGC5KgjAY"
      },
      "outputs": [],
      "source": [
        "zzwith tf.device(device_name):\n",
        "  from transformers import pipeline\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  import time\n",
        "  from sklearn.metrics import precision_recall_fscore_support\n",
        "  import csv\n",
        "  def classify_and_evaluate(df, model, tokenizer, llm_name, dataset_name):\n",
        "      torch.cuda.empty_cache()\n",
        "      model.to(device)\n",
        "      # Create a zero-shot classification pipeline\n",
        "      # Add a padding token to the tokenizer\n",
        "      tokenizer.pad_token = tokenizer.eos_token\n",
        "      # Add padding token to the model config\n",
        "      model.config.pad_token_id = tokenizer.pad_token_id\n",
        "      classifier = pipeline(\"zero-shot-classification\", model=model,  device = device, tokenizer=tokenizer, batch_size=2) #fix it to be running on GPU\n",
        "      candidate_labels = df['Label'].unique().tolist()\n",
        "      results = []\n",
        "      true_labels = []\n",
        "      predicted_labels = []\n",
        "\n",
        "      for _, row in df.iterrows():\n",
        "          req = row['RequirementText']\n",
        "          true_label = row['Label']\n",
        "          result = classifier(req, candidate_labels)\n",
        "          predicted_label = result['labels'][0]\n",
        "          results.append({\n",
        "              \"LLM\": llm_name,\n",
        "              \"Dataset_Type_Variation\": dataset_name,\n",
        "              \"Requirement\": req,\n",
        "              \"True Label\": true_label,\n",
        "              \"Predicted Label\": predicted_label,\n",
        "              \"Scores\": result['scores']\n",
        "          })\n",
        "          true_labels.append(true_label)\n",
        "          predicted_labels.append(predicted_label)\n",
        "\n",
        "      precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
        "      return results, precision, recall, f1\n",
        "\n",
        "  # Classify and evaluate for each dataset and model\n",
        "  all_results = []\n",
        "  evaluation_metrics = []\n",
        "  dataset_title = \"NFR-Thematic\"\n",
        "  datasets = [NFR_theme_1, NFR_theme_1_Remove_Punctuation, NFR_theme_1_Add_FullStops, NFR_theme_1_Labels_Uppercase, NFR_theme_1_Labels_Lowercase, NFR_theme_1_Labels_Capitalized,\n",
        "              NFR_theme_2, NFR_theme_2_Remove_Punctuation, NFR_theme_2_Add_FullStops, NFR_theme_2_Labels_Uppercase, NFR_theme_2_Labels_Lowercase, NFR_theme_2_Labels_Capitalized,\n",
        "              NFR_theme_3, NFR_theme_3_Remove_Punctuation, NFR_theme_3_Add_FullStops, NFR_theme_3_Labels_Uppercase, NFR_theme_3_Labels_Lowercase, NFR_theme_3_Labels_Capitalized,\n",
        "              NFR_theme_4, NFR_theme_4_Remove_Punctuation, NFR_theme_4_Add_FullStops, NFR_theme_4_Labels_Uppercase, NFR_theme_4_Labels_Lowercase, NFR_theme_4_Labels_Capitalized]\n",
        "  dataset_names = ['NFR-Performance-Reliability', 'NFR-Performance-Reliability-Remove_Punctuation', 'NFR-Performance-Reliability-Add_FullStops', 'NFR-Performance-Reliability-Labels_Uppercase', 'NFR-Performance-Reliability-Labels_Lowercase', 'NFR-Performance-Reliability-Labels_Capitalized',\n",
        "              'NFR-Usability-Experience', 'NFR-Usability-Experience-Remove_Punctuation', 'NFR-Usability-Experience-Add_FullStops', 'NFR-Usability-Experience-Labels_Uppercase', 'NFR-Usability-Experience-Labels_Lowercase', 'NFR-Usability-Experience-Labels_Capitalized',\n",
        "              'NFR-Operational-Maintenance', 'NFR-Operational-Maintenance-Remove_Punctuation', 'NFR-Operational-Maintenance-Add_FullStops', 'NFR-Operational-Maintenance-Labels_Uppercase', 'NFR-Operational-Maintenance-Labels_Lowercase', 'NFR-Operational-Maintenance-Labels_Capitalized',\n",
        "              'NFR-Legal-Security', 'NFR-Legal-Security-Remove_Punctuation', 'NFR-Legal-Security-Add_FullStops', 'NFR-Legal-Security-Labels_Uppercase', 'NFR-Legal-Security-Labels_Lowercase', 'NFR-Legal-Security-Labels_Capitalized']\n",
        "\n",
        "  '''\n",
        "  ################# Binary Classification Datasets #################\n",
        "\n",
        "  ##Functional Datasets\n",
        "  dataset_title = 'Functional'\n",
        "  datasets = [Functional_None, Functional_Add_FullStops, Functional_Remove_Punctuation, Functional_Labels_Uppercase, Functional_Labels_Lowercase, Functional_Labels_Capitalized]\n",
        "  dataset_names = ['Functional-Binary-None', 'Functional-Binary-Add_FullStops', 'Functional-Binary-Remove_Punctuation', 'Functional-Binary-Labels_Uppercase',\n",
        "                   'Functional-Binary-Labels_Lowercase', 'Functional-Binary-Labels_Capitalized']\n",
        "\n",
        "  ## Quality Datasets\n",
        "  dataset_title = 'Quality'\n",
        "  datasets = [Quality_None, Quality_Add_FullStops, Quality_Remove_Punctuation, Quality_Labels_Uppercase, Quality_Labels_Lowercase, Quality_Labels_Capitalized]\n",
        "  dataset_names = ['Quality-Binary-None', 'Quality-Binary-Add_FullStops', 'Quality-Binary-Remove_Punctuation', 'Quality-Binary-Labels_Uppercase',\n",
        "                   'Quality-Binary-Labels_Lowercase', 'Quality-Binary-Labels_Capitalized']\n",
        "\n",
        "\n",
        "  ## SeqReq Datasets\n",
        "  dataset_title = 'SeqReq'\n",
        "  datasets = [SeqReq_None, SeqReq_Add_FullStops, SeqReq_Remove_Punctuation, SeqReq_Labels_Uppercase, SeqReq_Labels_Lowercase, SeqReq_Labels_Capitalized]\n",
        "  dataset_names = ['SeqReq-Binary-None', 'SeqReq-Binary-Add_FullStops', 'SeqReq-Binary-Remove_Punctuation', 'SeqReq-Binary-Labels_Uppercase',\n",
        "                   'SeqReq-Binary-Labels_Lowercase', 'SeqReq-Binary-Labels_Capitalized']\n",
        "\n",
        "  ################# Multi-Classification Datasets #################\n",
        "\n",
        "  ## NFR Datasets\n",
        "  dataset_title = 'NFR'\n",
        "  datasets  = [NFR_None, NFR_Add_FullStops, NFR_Remove_Punctuation, NFR_Labels_Uppercase, NFR_Labels_Lowercase, NFR_Labels_Capitalized]\n",
        "  dataset_names = ['NFR-Multi-None', 'NFR-Multi-Add_FullStops', 'NFR-Multi-Remove_Punctuation', 'NFR-Multi-Labels_Uppercase',\n",
        "                   'NFR-Multi-Labels_Lowercase', 'NFR-Multi-Labels_Capitalized']\n",
        "\n",
        "  dataset_title = \"NFR-NoFunc\"\n",
        "  datasets = [NFR_None_NoFunc, NFR_Add_FullStops_NoFunc, NFR_Remove_Punctuation_NoFunc, NFR_Labels_Uppercase_NoFunc, NFR_Labels_Lowercase_NoFunc, NFR_Labels_Capitalized_NoFunc]\n",
        "  dataset_names = ['NFR-Multi-None', 'NFR-Multi-Add_FullStops', 'NFR-Multi-Remove_Punctuation', 'NFR-Multi-Labels_Uppercase', 'NFR-Multi-Labels_Lowercase', 'NFR-Multi-Labels_Capitalized']\n",
        "\n",
        "  dataset_title = \"NFR-Thematic\"\n",
        "  datasets = [NFR_theme_1, NFR_theme_1_Remove_Punctuation, NFR_theme_1_Add_FullStops, NFR_theme_1_Labels_Uppercase, NFR_theme_1_Labels_Lowercase, NFR_theme_1_Labels_Capitalized,\n",
        "              NFR_theme_2, NFR_theme_2_Remove_Punctuation, NFR_theme_2_Add_FullStops, NFR_theme_2_Labels_Uppercase, NFR_theme_2_Labels_Lowercase, NFR_theme_2_Labels_Capitalized,\n",
        "              NFR_theme_3, NFR_theme_3_Remove_Punctuation, NFR_theme_3_Add_FullStops, NFR_theme_3_Labels_Uppercase, NFR_theme_3_Labels_Lowercase, NFR_theme_3_Labels_Capitalized,\n",
        "              NFR_theme_4, NFR_theme_4_Remove_Punctuation, NFR_theme_4_Add_FullStops, NFR_theme_4_Labels_Uppercase, NFR_theme_4_Labels_Lowercase, NFR_theme_4_Labels_Capitalized]\n",
        "  dataset_names = ['NFR-Performance-Reliability', 'NFR-Performance-Reliability-Remove_Punctuation', 'NFR-Performance-Reliability-Add_FullStops', 'NFR-Performance-Reliability-Labels_Uppercase', 'NFR-Performance-Reliability-Labels_Lowercase', 'NFR-Performance-Reliability-Labels_Capitalized',\n",
        "              'NFR-Usability-Experience', 'NFR-Usability-Experience-Remove_Punctuation', 'NFR-Usability-Experience-Add_FullStops', 'NFR-Usability-Experience-Labels_Uppercase', 'NFR-Usability-Experience-Labels_Lowercase', 'NFR-Usability-Experience-Labels_Capitalized',\n",
        "              'NFR-Operational-Maintenance', 'NFR-Operational-Maintenance-Remove_Punctuation', 'NFR-Operational-Maintenance-Add_FullStops', 'NFR-Operational-Maintenance-Labels_Uppercase', 'NFR-Operational-Maintenance-Labels_Lowercase', 'NFR-Operational-Maintenance-Labels_Capitalized',\n",
        "              'NFR-Legal-Security', 'NFR-Legal-Security-Remove_Punctuation', 'NFR-Legal-Security-Add_FullStops', 'NFR-Legal-Security-Labels_Uppercase', 'NFR-Legal-Security-Labels_Lowercase', 'NFR-Legal-Security-Labels_Capitalized']\n",
        "\n",
        "\n",
        "  ################# OVR-Classification Datasets (NOT USED) #################\n",
        "  ## OVR-Classification NFR dataset except Functional\n",
        "\n",
        "  dataset_title = \"NFR-NoFunc-OVR\"\n",
        "  datasets = [Performance_NFR_None_NoFunc, Performance_NFR_None_NoFunc_Remove_Punctuation, Performance_NFR_None_NoFunc_Add_FullStops, Performance_NFR_None_NoFunc_Labels_Uppercase, Performance_NFR_None_NoFunc_Labels_Lowercase, Performance_NFR_None_NoFunc_Labels_Capitalized,\n",
        "  Availability_NFR_None_NoFunc, Availability_NFR_None_NoFunc_Remove_Punctuation,  Availability_NFR_None_NoFunc_Add_FullStops, Availability_NFR_None_NoFunc_Labels_Uppercase, Availability_NFR_None_NoFunc_Labels_Lowercase, Availability_NFR_None_NoFunc_Labels_Capitalized,\n",
        "  Operational_NFR_None_NoFunc, Operational_NFR_None_NoFunc_Remove_Punctuation, Operational_NFR_None_NoFunc_Add_FullStops, Operational_NFR_None_NoFunc_Labels_Uppercase, Operational_NFR_None_NoFunc_Labels_Lowercase, Operational_NFR_None_NoFunc_Labels_Capitalized,\n",
        "  Usability_NFR_None_NoFunc, Usability_NFR_None_NoFunc_Remove_Punctuation, Usability_NFR_None_NoFunc_Add_FullStops, Usability_NFR_None_NoFunc_Labels_Uppercase, Usability_NFR_None_NoFunc_Labels_Lowercase, Usability_NFR_None_NoFunc_Labels_Capitalized,\n",
        "  Maintainability_NFR_None_NoFunc, Maintainability_NFR_None_NoFunc_Remove_Punctuation, Maintainability_NFR_None_NoFunc_Add_FullStops, Maintainability_NFR_None_NoFunc_Labels_Uppercase, Maintainability_NFR_None_NoFunc_Labels_Lowercase, Maintainability_NFR_None_NoFunc_Labels_Capitalized, Scalability_NFR_None_NoFunc_Remove_Punctuation,\n",
        "  Scalability_NFR_None_NoFunc, Scalability_NFR_None_NoFunc_Add_FullStops, Scalability_NFR_None_NoFunc_Labels_Uppercase, Scalability_NFR_None_NoFunc_Labels_Lowercase, Scalability_NFR_None_NoFunc_Labels_Capitalized,\n",
        "  Portability_NFR_None_NoFunc, Portability_NFR_None_NoFunc_Remove_Punctuation, Portability_NFR_None_NoFunc_Add_FullStops, Portability_NFR_None_NoFunc_Labels_Uppercase, Portability_NFR_None_NoFunc_Labels_Lowercase, Portability_NFR_None_NoFunc_Labels_Capitalized,\n",
        "  Security_NFR_None_NoFunc, Security_NFR_None_NoFunc_Remove_Punctuation, Security_NFR_None_NoFunc_Add_FullStops, Security_NFR_None_NoFunc_Labels_Uppercase, Security_NFR_None_NoFunc_Labels_Lowercase, Security_NFR_None_NoFunc_Labels_Capitalized,\n",
        "  Legal_NFR_None_NoFunc, Legal_NFR_None_NoFunc_Remove_Punctuation,  Legal_NFR_None_NoFunc_Add_FullStops, Legal_NFR_None_NoFunc_Labels_Uppercase, Legal_NFR_None_NoFunc_Labels_Lowercase, Legal_NFR_None_NoFunc_Labels_Capitalized,\n",
        "  Fault_Tolerance_NFR_None_NoFunc, Fault_Tolerance_NFR_None_NoFunc_Remove_Punctuation, Fault_Tolerance_NFR_None_NoFunc_Add_FullStops, Fault_Tolerance_NFR_None_NoFunc_Labels_Uppercase, Fault_Tolerance_NFR_None_NoFunc_Labels_Lowercase, Fault_Tolerance_NFR_None_NoFunc_Labels_Capitalized]\n",
        "\n",
        "  dataset_names = ['Performance-NFR-None', 'Performance-NFR-Add_FullStops', 'Performance-NFR-Labels_Uppercase', 'Performance-NFR-Labels_Lowercase', 'Performance-NFR-Labels_Capitalized',\n",
        "              'Availability-NFR-None', 'Availability-NFR-Add_FullStops', 'Availability-NFR-Labels_Uppercase', 'Availability-NFR-Labels_Lowercase', 'Availability-NFR-Labels_Capitalized',\n",
        "              'Operational-NFR-None', 'Operational-NFR-Add_FullStops', 'Operational-NFR-Labels_Uppercase', 'Operational-NFR-Labels_Lowercase', 'Operational-NFR-Labels_Capitalized',\n",
        "              'Usability-NFR-None', 'Usability-NFR-Add_FullStops', 'Usability-NFR-Labels_Uppercase', 'Usability-NFR-Labels_Lowercase', 'Usability-NFR-Labels_Capitalized',\n",
        "              'Maintainability-NFR-None', 'Maintainability-NFR-Add_FullStops', 'Maintainability-NFR-Labels_Uppercase', 'Maintainability-NFR-Labels_Lowercase', 'Maintainability-NFR-Labels_Capitalized',\n",
        "              'Scalability-NFR-None', 'Scalability-NFR-Add_FullStops', 'Scalability-NFR-Labels_Uppercase', 'Scalability-NFR-Labels_Lowercase', 'Scalability-NFR-Labels_Capitalized',\n",
        "              'Portability-NFR-None', 'Portability-NFR-Add_FullStops', 'Portability-NFR-Labels_Uppercase', 'Portability-NFR-Labels_Lowercase', 'Portability-NFR-Labels_Capitalized',\n",
        "              'Security-NFR-None', 'Security-NFR-Add_FullStops', 'Security-NFR-Labels_Uppercase', 'Security-NFR-Labels_Lowercase', 'Security-NFR-Labels_Capitalized',\n",
        "              'Legal-NFR-None', 'Legal-NFR-Add_FullStops', 'Legal-NFR-Labels_Uppercase', 'Legal-NFR-Labels_Lowercase', 'Legal-NFR-Labels_Capitalized',\n",
        "              'Fault_Tolerance_NFR-None', 'Fault_Tolerance_NFR-Add_FullStops', 'Fault_Tolerance_NFR-Labels_Uppercase', 'Fault_Tolerance_NFR-Labels_Lowercase', 'Fault_Tolerance_NFR-Labels_Capitalized']\n",
        "\n",
        "  ################# Combined Dataset (NOT COMPLETED) #################\n",
        "  ## Combined Datasets\n",
        "  dataset_title = 'Combined'\n",
        "  datasets = [Functional_None, Functional_Add_FullStops, Functional_Remove_Punctuation, Functional_Labels_Uppercase, Functional_Labels_Lowercase, Functional_Labels_Capitalized,\n",
        "              Quality_None, Quality_Add_FullStops, Quality_Remove_Punctuation, Quality_Labels_Uppercase, Quality_Labels_Lowercase, Quality_Labels_Capitalized,\n",
        "              SeqReq_None, SeqReq_Add_FullStops, SeqReq_Remove_Punctuation, SeqReq_Labels_Uppercase, SeqReq_Labels_Lowercase, SeqReq_Labels_Capitalized,\n",
        "              NFR_None, NFR_Add_FullStops, NFR_Remove_Punctuation, NFR_Labels_Uppercase, NFR_Labels_Lowercase, NFR_Labels_Capitalized]\n",
        "  dataset_names = ['Functional-Binary-None', 'Functional-Binary-Add_FullStops', 'Functional-Binary-Remove_Punctuation', 'Functional-Binary-Labels_Uppercase', 'Functional-Binary-Labels_Lowercase', 'Functional-Binary-Labels_Capitalized',\n",
        "                   'Quality-Binary-None', 'Quality-Binary-Add_FullStops', 'Quality-Binary-Remove_Punctuation', 'Quality-Binary-Labels_Uppercase', 'Quality-Binary-Labels_Lowercase', 'Quality-Binary-Labels_Capitalized',\n",
        "                   'SeqReq-Binary-None', 'SeqReq-Binary-Add_FullStops', 'SeqReq-Binary-Remove_Punctuation', 'SeqReq-Binary-Labels_Uppercase', 'SeqReq-Binary-Labels_Lowercase', 'SeqReq-Binary-Labels_Capitalized',\n",
        "                   'NFR-Multi-None', 'NFR-Multi-Add_FullStops', 'NFR-Multi-Remove_Punctuation', 'NFR-Multi-Labels_Uppercase', 'NFR-Multi-Labels_Lowercase', 'NFR-Multi-Labels_Capitalized']\n",
        "\n",
        "  '''\n",
        "\n",
        "\n",
        "  for i, dataset in enumerate(datasets):\n",
        "      start_time = time.time()\n",
        "      print(f\"Classifying and evaluating for {dataset_names[i]} dataset...\")\n",
        "      profiler = LineProfiler()\n",
        "      profiler.add_function(classify_and_evaluate)\n",
        "      profiler.enable_by_count()\n",
        "      dataset_name = dataset_names[i]\n",
        "      for j, (model, tokenizer) in enumerate(models_and_tokenizers):\n",
        "          print(f\"Classifying and evaluating for {llms_shortnames[j]} model...\")\n",
        "          llm_name = llms_shortnames[j]\n",
        "          results, precision, recall, f1 = classify_and_evaluate(dataset, model, tokenizer, llm_name, dataset_name)\n",
        "          profiler.disable_by_count()\n",
        "          profiler.print_stats()\n",
        "          all_results.extend(results)\n",
        "          print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
        "          end_time = time.time()\n",
        "          elapsed_time = end_time - start_time\n",
        "          # Format elapsed time as HH:MM:SS\n",
        "          hours = int(elapsed_time // 3600)\n",
        "          minutes = int((elapsed_time % 3600) // 60)\n",
        "          seconds = int(elapsed_time % 60)\n",
        "          time_string = f\"Total execution time: {hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "          print(time_string)\n",
        "          evaluation_metrics.append({\n",
        "              \"LLM\": llm_name,\n",
        "              \"Dataset_Type_Variation\": dataset_name,\n",
        "              \"Precision\": precision,\n",
        "              \"Recall\": recall,\n",
        "              \"F1-Score\": f1,\n",
        "              \"Execution Time\": time_string\n",
        "          })\n",
        "\n",
        "  # Save classification results to CSV\n",
        "  with open(dataset_title+'_'+ llm_name+'_ZSL_HFpipeline_classification_results_Template_None.csv', 'w', newline='') as csvfile:\n",
        "      fieldnames = [\"LLM\", \"Dataset_Type_Variation\", \"Requirement\", \"True Label\", \"Predicted Label\", \"Scores\"]\n",
        "      writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "      writer.writeheader()\n",
        "      writer.writerows(all_results)\n",
        "\n",
        "  # Save evaluation metrics to CSV\n",
        "  with open(dataset_title+'_'+ llm_name+'_ZSL_HFpipeline_evaluation_metrics_Template_None.csv', 'w', newline='') as csvfile:\n",
        "      fieldnames = [\"LLM\", \"Dataset_Type_Variation\", \"Precision\", \"Recall\", \"F1-Score\", \"Execution Time\"]\n",
        "      writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "      writer.writeheader()\n",
        "      writer.writerows(evaluation_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM4eP4746GK5"
      },
      "outputs": [],
      "source": [
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnNFIVtrTHA1"
      },
      "source": [
        "#Saved Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM_sa9fI-Fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "1baafec6-d72b-429a-f172-d71f285ded7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: .config/ (stored 0%)\n",
            "  adding: .config/configurations/ (stored 0%)\n",
            "  adding: .config/configurations/config_default (deflated 15%)\n",
            "  adding: .config/gce (stored 0%)\n",
            "  adding: .config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "  adding: .config/.last_update_check.json (deflated 22%)\n",
            "  adding: .config/logs/ (stored 0%)\n",
            "  adding: .config/logs/2024.11.21/ (stored 0%)\n",
            "  adding: .config/logs/2024.11.21/14.25.30.368557.log (deflated 87%)\n",
            "  adding: .config/logs/2024.11.21/14.25.43.887178.log (deflated 57%)\n",
            "  adding: .config/logs/2024.11.21/14.25.31.482956.log (deflated 58%)\n",
            "  adding: .config/logs/2024.11.21/14.25.44.623490.log (deflated 56%)\n",
            "  adding: .config/logs/2024.11.21/14.24.55.851126.log (deflated 92%)\n",
            "  adding: .config/logs/2024.11.21/14.25.17.504089.log (deflated 58%)\n",
            "  adding: .config/config_sentinel (stored 0%)\n",
            "  adding: .config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: .config/active_config (stored 0%)\n",
            "  adding: .config/default_configs.db (deflated 98%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Labels_Capitalized_Llama_ZSL_Torch_classification_results_Template.csv (deflated 69%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Labels_Uppercase_Llama_ZSL_Torch_evaluation_metrics_Template.csv (deflated 62%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Labels_Lowercase_Llama_ZSL_Torch_classification_results_Template.csv (deflated 69%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Labels_Capitalized_Llama_ZSL_Torch_evaluation_metrics_Template.csv (deflated 61%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Labels_Uppercase_Llama_ZSL_Torch_classification_results_Template.csv (deflated 69%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Add_FullStops_Llama_ZSL_Torch_classification_results_Template.csv (deflated 69%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Labels_Lowercase_Llama_ZSL_Torch_evaluation_metrics_Template.csv (deflated 61%)\n",
            "  adding: PROMISE-NFR-v2.csv (deflated 75%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Remove_Punctuation_Llama_ZSL_Torch_classification_results_Template.csv (deflated 69%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Add_FullStops_Llama_ZSL_Torch_evaluation_metrics_Template.csv (deflated 61%)\n",
            "  adding: NFR-multi-classification_NFR-Multi-Remove_Punctuation_Llama_ZSL_Torch_evaluation_metrics_Template.csv (deflated 62%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d727cb27-b925-4811-b0cd-e590108c67e8\", \"NFR-multi-classification-Llama_all.zip\", 2705015)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Download all the files in this colab except sample_data into zipped folder\n",
        "from google.colab import files\n",
        "\n",
        "!zip -r {'NFR-multi-classification-'+ llm_name+'_all.zip'} . -x \"sample_data/*\"\n",
        "files.download('NFR-multi-classification-'+ llm_name+'_all.zip')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "W19TpOVbpUWk",
        "AGLneov8pgKv",
        "JjS9dM_xpzTN",
        "2KtWAs16I3bg",
        "VEx6DVmCNGUj"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}